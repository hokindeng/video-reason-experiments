==========================================
Job ID: 1802691
Job Name: hunyuan-G1
Node: gh134
Start Time: Sun 11 Jan 2026 06:50:27 PM CST
Working Directory: /u/yli8/hokin/video-reason-experiments/jobs
==========================================

Loaded modules:

GPU Information:
Sun Jan 11 18:50:27 2026       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.163.01             Driver Version: 550.163.01     CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA GH200 120GB             On  |   00000029:01:00.0 Off |                    0 |
| N/A   22C    P0             94W /  900W |      14MiB /  97871MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+

Starting inference...
Model: hunyuan-video-i2v
Task: G-1_object_trajectory_data-generator
Questions dir: ./data/questions/G-1_object_trajectory_data-generator

üéØ VMEvalKit Inference Runner
Model: hunyuan-video-i2v
GPU: 0
Questions dir: /u/yli8/hokin/video-reason-experiments/data/questions/G-1_object_trajectory_data-generator
Output dir: /u/yli8/hokin/video-reason-experiments/data/outputs

üöÄ Running: python /u/yli8/hokin/video-reason-experiments/VMEvalKit/examples/generate_videos.py --model hunyuan-video-i2v --questions-dir /u/yli8/hokin/video-reason-experiments/data/questions/G-1_object_trajectory_data-generator --output-dir /u/yli8/hokin/video-reason-experiments/data/outputs --gpu 0
Working directory: /u/yli8/hokin/video-reason-experiments/VMEvalKit
================================================================================
üêç Activating venv: /u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v
üéÆ Using GPU 0 (CUDA_VISIBLE_DEVICES=0)
üîç Discovering human-approved tasks from folder structure...
üîç Discovering tasks from: /u/yli8/hokin/video-reason-experiments/data/questions/G-1_object_trajectory_data-generator
   üìÅ Scanning object_trajectory_task/
      ‚úÖ Found 50 tasks in object_trajectory

üìä Discovery Summary: 50 total tasks
   object_trajectory: 50 tasks
   üéØ Running all discovered tasks

üéØ Selected 1 model(s): hunyuan-video-i2v

üîç Verifying 1 model(s) for testing...
   ‚úÖ hunyuan-video-i2v: HunyuanVideo
üöÄ VMEVAL KIT EXPERIMENT - CLEAN EXECUTION

üìä Experiment Configuration:
   Models to run: 1 - hunyuan-video-i2v
   Domains: 1
   üîÑ Execution Mode: SEQUENTIAL

üìà Task Distribution:
   Object_Trajectory: 50 approved tasks
   Total approved tasks: 50
   Total generations: 50

üìÅ Output directory: /u/yli8/hokin/video-reason-experiments/data/outputs
   Skip existing: True

üìÅ Output directory structure ready at: /u/yli8/hokin/video-reason-experiments/data/outputs
   Each inference will create a self-contained folder with:
   - video/: Generated video file
   - question/: Input images and prompt
   - metadata.json: Complete inference metadata
üìÅ Created per-model folders under: /u/yli8/hokin/video-reason-experiments/data/outputs and mirrored question tasks
üìã Total inference jobs to run: 50
üöÄ Starting sequential execution...

   Processing order: Model by model, task by task

ü§ñ Processing Model: HunyuanVideo (hunyuan-video-i2v)

  üìö Domain: Object_Trajectory
    [1/50] Processing: object_trajectory_0000

  üé¨ Generating: object_trajectory_0000 with hunyuan-video-i2v
     Image: /u/yli8/hokin/video-reason-experiments/data/questions/G-1_object_trajectory_data-generator/object_trajectory_task/object_trajectory_0000/first_frame.png
     Prompt: The scene contains a circle object and a dashed target position (indicated by a ...
Using model-specific Python: /u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/bin/python
üì¶ Loaded model: hunyuan-video-i2v (will be reused for all tasks)
Warning: HunyuanVideo requires 60-80GB GPU memory for 720p generation

‚úÖ Inference complete! Output saved to: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0000
   - Generated: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0000/video/video.mp4
   - Question: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0000/question/
     ‚ùå Failed: Traceback (most recent call last):
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/sample_image2video.py", line 8, in <module>
    from hyvideo.config import parse_args
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/config.py", line 4, in <module>
    from .modules.models import HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/__init__.py", line 1, in <module>
    from .models import HYVideoDiffusionTransformer, HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/models.py", line 15, in <module>
    from .embed_layers import TimestepEmbedder, PatchEmbed, TextProjection
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/embed_layers.py", line 6, in <module>
    from ..utils.helpers import to_2tuple
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/utils/helpers.py", line 11, in <module>
    import deepspeed
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/__init__.py", line 9, in <module>
    from .runtime.engine import DeepSpeedEngine
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/engine.py", line 12, in <module>
    from tensorboardX import SummaryWriter
ModuleNotFoundError: No module named 'tensorboardX'

      ‚ùå Failed: Traceback (most recent call last):
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/sample_image2video.py", line 8, in <module>
    from hyvideo.config import parse_args
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/config.py", line 4, in <module>
    from .modules.models import HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/__init__.py", line 1, in <module>
    from .models import HYVideoDiffusionTransformer, HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/models.py", line 15, in <module>
    from .embed_layers import TimestepEmbedder, PatchEmbed, TextProjection
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/embed_layers.py", line 6, in <module>
    from ..utils.helpers import to_2tuple
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/utils/helpers.py", line 11, in <module>
    import deepspeed
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/__init__.py", line 9, in <module>
    from .runtime.engine import DeepSpeedEngine
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/engine.py", line 12, in <module>
    from tensorboardX import SummaryWriter
ModuleNotFoundError: No module named 'tensorboardX'

    [2/50] Processing: object_trajectory_0001

  üé¨ Generating: object_trajectory_0001 with hunyuan-video-i2v
     Image: /u/yli8/hokin/video-reason-experiments/data/questions/G-1_object_trajectory_data-generator/object_trajectory_task/object_trajectory_0001/first_frame.png
     Prompt: The scene contains a square object and a dashed target position (indicated by a ...
Warning: HunyuanVideo requires 60-80GB GPU memory for 720p generation

‚úÖ Inference complete! Output saved to: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0001
   - Generated: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0001/video/video.mp4
   - Question: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0001/question/
     ‚ùå Failed: Traceback (most recent call last):
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/sample_image2video.py", line 8, in <module>
    from hyvideo.config import parse_args
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/config.py", line 4, in <module>
    from .modules.models import HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/__init__.py", line 1, in <module>
    from .models import HYVideoDiffusionTransformer, HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/models.py", line 15, in <module>
    from .embed_layers import TimestepEmbedder, PatchEmbed, TextProjection
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/embed_layers.py", line 6, in <module>
    from ..utils.helpers import to_2tuple
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/utils/helpers.py", line 11, in <module>
    import deepspeed
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/__init__.py", line 9, in <module>
    from .runtime.engine import DeepSpeedEngine
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/engine.py", line 12, in <module>
    from tensorboardX import SummaryWriter
ModuleNotFoundError: No module named 'tensorboardX'

      ‚ùå Failed: Traceback (most recent call last):
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/sample_image2video.py", line 8, in <module>
    from hyvideo.config import parse_args
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/config.py", line 4, in <module>
    from .modules.models import HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/__init__.py", line 1, in <module>
    from .models import HYVideoDiffusionTransformer, HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/models.py", line 15, in <module>
    from .embed_layers import TimestepEmbedder, PatchEmbed, TextProjection
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/embed_layers.py", line 6, in <module>
    from ..utils.helpers import to_2tuple
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/utils/helpers.py", line 11, in <module>
    import deepspeed
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/__init__.py", line 9, in <module>
    from .runtime.engine import DeepSpeedEngine
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/engine.py", line 12, in <module>
    from tensorboardX import SummaryWriter
ModuleNotFoundError: No module named 'tensorboardX'

    [3/50] Processing: object_trajectory_0002

  üé¨ Generating: object_trajectory_0002 with hunyuan-video-i2v
     Image: /u/yli8/hokin/video-reason-experiments/data/questions/G-1_object_trajectory_data-generator/object_trajectory_task/object_trajectory_0002/first_frame.png
     Prompt: The scene contains a circle object and a dashed target position (indicated by a ...
Warning: HunyuanVideo requires 60-80GB GPU memory for 720p generation

‚úÖ Inference complete! Output saved to: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0002
   - Generated: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0002/video/video.mp4
   - Question: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0002/question/
     ‚ùå Failed: Traceback (most recent call last):
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/sample_image2video.py", line 8, in <module>
    from hyvideo.config import parse_args
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/config.py", line 4, in <module>
    from .modules.models import HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/__init__.py", line 1, in <module>
    from .models import HYVideoDiffusionTransformer, HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/models.py", line 15, in <module>
    from .embed_layers import TimestepEmbedder, PatchEmbed, TextProjection
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/embed_layers.py", line 6, in <module>
    from ..utils.helpers import to_2tuple
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/utils/helpers.py", line 11, in <module>
    import deepspeed
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/__init__.py", line 9, in <module>
    from .runtime.engine import DeepSpeedEngine
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/engine.py", line 12, in <module>
    from tensorboardX import SummaryWriter
ModuleNotFoundError: No module named 'tensorboardX'

      ‚ùå Failed: Traceback (most recent call last):
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/sample_image2video.py", line 8, in <module>
    from hyvideo.config import parse_args
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/config.py", line 4, in <module>
    from .modules.models import HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/__init__.py", line 1, in <module>
    from .models import HYVideoDiffusionTransformer, HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/models.py", line 15, in <module>
    from .embed_layers import TimestepEmbedder, PatchEmbed, TextProjection
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/embed_layers.py", line 6, in <module>
    from ..utils.helpers import to_2tuple
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/utils/helpers.py", line 11, in <module>
    import deepspeed
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/__init__.py", line 9, in <module>
    from .runtime.engine import DeepSpeedEngine
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/engine.py", line 12, in <module>
    from tensorboardX import SummaryWriter
ModuleNotFoundError: No module named 'tensorboardX'

    [4/50] Processing: object_trajectory_0003

  üé¨ Generating: object_trajectory_0003 with hunyuan-video-i2v
     Image: /u/yli8/hokin/video-reason-experiments/data/questions/G-1_object_trajectory_data-generator/object_trajectory_task/object_trajectory_0003/first_frame.png
     Prompt: The scene contains a triangle object and a dashed target position (indicated by ...
Warning: HunyuanVideo requires 60-80GB GPU memory for 720p generation

‚úÖ Inference complete! Output saved to: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0003
   - Generated: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0003/video/video.mp4
   - Question: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0003/question/
     ‚ùå Failed: Traceback (most recent call last):
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/sample_image2video.py", line 8, in <module>
    from hyvideo.config import parse_args
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/config.py", line 4, in <module>
    from .modules.models import HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/__init__.py", line 1, in <module>
    from .models import HYVideoDiffusionTransformer, HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/models.py", line 15, in <module>
    from .embed_layers import TimestepEmbedder, PatchEmbed, TextProjection
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/embed_layers.py", line 6, in <module>
    from ..utils.helpers import to_2tuple
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/utils/helpers.py", line 11, in <module>
    import deepspeed
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/__init__.py", line 9, in <module>
    from .runtime.engine import DeepSpeedEngine
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/engine.py", line 12, in <module>
    from tensorboardX import SummaryWriter
ModuleNotFoundError: No module named 'tensorboardX'

      ‚ùå Failed: Traceback (most recent call last):
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/sample_image2video.py", line 8, in <module>
    from hyvideo.config import parse_args
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/config.py", line 4, in <module>
    from .modules.models import HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/__init__.py", line 1, in <module>
    from .models import HYVideoDiffusionTransformer, HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/models.py", line 15, in <module>
    from .embed_layers import TimestepEmbedder, PatchEmbed, TextProjection
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/embed_layers.py", line 6, in <module>
    from ..utils.helpers import to_2tuple
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/utils/helpers.py", line 11, in <module>
    import deepspeed
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/__init__.py", line 9, in <module>
    from .runtime.engine import DeepSpeedEngine
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/engine.py", line 12, in <module>
    from tensorboardX import SummaryWriter
ModuleNotFoundError: No module named 'tensorboardX'

    [5/50] Processing: object_trajectory_0004

  üé¨ Generating: object_trajectory_0004 with hunyuan-video-i2v
     Image: /u/yli8/hokin/video-reason-experiments/data/questions/G-1_object_trajectory_data-generator/object_trajectory_task/object_trajectory_0004/first_frame.png
     Prompt: The scene contains a square object and a dashed target position (indicated by a ...
Warning: HunyuanVideo requires 60-80GB GPU memory for 720p generation

‚úÖ Inference complete! Output saved to: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0004
   - Generated: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0004/video/video.mp4
   - Question: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0004/question/
     ‚ùå Failed: Traceback (most recent call last):
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/sample_image2video.py", line 8, in <module>
    from hyvideo.config import parse_args
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/config.py", line 4, in <module>
    from .modules.models import HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/__init__.py", line 1, in <module>
    from .models import HYVideoDiffusionTransformer, HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/models.py", line 15, in <module>
    from .embed_layers import TimestepEmbedder, PatchEmbed, TextProjection
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/embed_layers.py", line 6, in <module>
    from ..utils.helpers import to_2tuple
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/utils/helpers.py", line 11, in <module>
    import deepspeed
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/__init__.py", line 9, in <module>
    from .runtime.engine import DeepSpeedEngine
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/engine.py", line 14, in <module>
    from deepspeed.runtime.zero.stage2 import FP16_DeepSpeedZeroOptimizer
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/zero/stage2.py", line 10, in <module>
    from torch._six import inf
ModuleNotFoundError: No module named 'torch._six'

      ‚ùå Failed: Traceback (most recent call last):
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/sample_image2video.py", line 8, in <module>
    from hyvideo.config import parse_args
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/config.py", line 4, in <module>
    from .modules.models import HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/__init__.py", line 1, in <module>
    from .models import HYVideoDiffusionTransformer, HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/models.py", line 15, in <module>
    from .embed_layers import TimestepEmbedder, PatchEmbed, TextProjection
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/embed_layers.py", line 6, in <module>
    from ..utils.helpers import to_2tuple
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/utils/helpers.py", line 11, in <module>
    import deepspeed
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/__init__.py", line 9, in <module>
    from .runtime.engine import DeepSpeedEngine
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/engine.py", line 14, in <module>
    from deepspeed.runtime.zero.stage2 import FP16_DeepSpeedZeroOptimizer
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/zero/stage2.py", line 10, in <module>
    from torch._six import inf
ModuleNotFoundError: No module named 'torch._six'

    [6/50] Processing: object_trajectory_0005

  üé¨ Generating: object_trajectory_0005 with hunyuan-video-i2v
     Image: /u/yli8/hokin/video-reason-experiments/data/questions/G-1_object_trajectory_data-generator/object_trajectory_task/object_trajectory_0005/first_frame.png
     Prompt: The scene contains a square object and a dashed target position (indicated by a ...
Warning: HunyuanVideo requires 60-80GB GPU memory for 720p generation

‚úÖ Inference complete! Output saved to: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0005
   - Generated: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0005/video/video.mp4
   - Question: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0005/question/
     ‚ùå Failed: Traceback (most recent call last):
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/sample_image2video.py", line 8, in <module>
    from hyvideo.config import parse_args
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/config.py", line 4, in <module>
    from .modules.models import HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/__init__.py", line 1, in <module>
    from .models import HYVideoDiffusionTransformer, HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/models.py", line 15, in <module>
    from .embed_layers import TimestepEmbedder, PatchEmbed, TextProjection
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/embed_layers.py", line 6, in <module>
    from ..utils.helpers import to_2tuple
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/utils/helpers.py", line 11, in <module>
    import deepspeed
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/__init__.py", line 9, in <module>
    from .runtime.engine import DeepSpeedEngine
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/engine.py", line 14, in <module>
    from deepspeed.runtime.zero.stage2 import FP16_DeepSpeedZeroOptimizer
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/zero/stage2.py", line 10, in <module>
    from torch._six import inf
ModuleNotFoundError: No module named 'torch._six'

      ‚ùå Failed: Traceback (most recent call last):
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/sample_image2video.py", line 8, in <module>
    from hyvideo.config import parse_args
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/config.py", line 4, in <module>
    from .modules.models import HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/__init__.py", line 1, in <module>
    from .models import HYVideoDiffusionTransformer, HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/models.py", line 15, in <module>
    from .embed_layers import TimestepEmbedder, PatchEmbed, TextProjection
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/embed_layers.py", line 6, in <module>
    from ..utils.helpers import to_2tuple
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/utils/helpers.py", line 11, in <module>
    import deepspeed
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/__init__.py", line 9, in <module>
    from .runtime.engine import DeepSpeedEngine
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/engine.py", line 14, in <module>
    from deepspeed.runtime.zero.stage2 import FP16_DeepSpeedZeroOptimizer
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/zero/stage2.py", line 10, in <module>
    from torch._six import inf
ModuleNotFoundError: No module named 'torch._six'

    [7/50] Processing: object_trajectory_0006

  üé¨ Generating: object_trajectory_0006 with hunyuan-video-i2v
     Image: /u/yli8/hokin/video-reason-experiments/data/questions/G-1_object_trajectory_data-generator/object_trajectory_task/object_trajectory_0006/first_frame.png
     Prompt: The scene contains a circle object and a dashed target position (indicated by a ...
Warning: HunyuanVideo requires 60-80GB GPU memory for 720p generation

‚úÖ Inference complete! Output saved to: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0006
   - Generated: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0006/video/video.mp4
   - Question: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0006/question/
     ‚ùå Failed: Traceback (most recent call last):
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/sample_image2video.py", line 8, in <module>
    from hyvideo.config import parse_args
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/config.py", line 4, in <module>
    from .modules.models import HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/__init__.py", line 1, in <module>
    from .models import HYVideoDiffusionTransformer, HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/models.py", line 15, in <module>
    from .embed_layers import TimestepEmbedder, PatchEmbed, TextProjection
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/embed_layers.py", line 6, in <module>
    from ..utils.helpers import to_2tuple
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/utils/helpers.py", line 11, in <module>
    import deepspeed
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/__init__.py", line 9, in <module>
    from .runtime.engine import DeepSpeedEngine
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/engine.py", line 14, in <module>
    from deepspeed.runtime.zero.stage2 import FP16_DeepSpeedZeroOptimizer
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/zero/stage2.py", line 10, in <module>
    from torch._six import inf
ModuleNotFoundError: No module named 'torch._six'

      ‚ùå Failed: Traceback (most recent call last):
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/sample_image2video.py", line 8, in <module>
    from hyvideo.config import parse_args
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/config.py", line 4, in <module>
    from .modules.models import HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/__init__.py", line 1, in <module>
    from .models import HYVideoDiffusionTransformer, HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/models.py", line 15, in <module>
    from .embed_layers import TimestepEmbedder, PatchEmbed, TextProjection
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/embed_layers.py", line 6, in <module>
    from ..utils.helpers import to_2tuple
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/utils/helpers.py", line 11, in <module>
    import deepspeed
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/__init__.py", line 9, in <module>
    from .runtime.engine import DeepSpeedEngine
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/engine.py", line 14, in <module>
    from deepspeed.runtime.zero.stage2 import FP16_DeepSpeedZeroOptimizer
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/zero/stage2.py", line 10, in <module>
    from torch._six import inf
ModuleNotFoundError: No module named 'torch._six'

    [8/50] Processing: object_trajectory_0007

  üé¨ Generating: object_trajectory_0007 with hunyuan-video-i2v
     Image: /u/yli8/hokin/video-reason-experiments/data/questions/G-1_object_trajectory_data-generator/object_trajectory_task/object_trajectory_0007/first_frame.png
     Prompt: The scene contains a diamond object and a dashed target position (indicated by a...
Warning: HunyuanVideo requires 60-80GB GPU memory for 720p generation

‚úÖ Inference complete! Output saved to: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0007
   - Generated: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0007/video/video.mp4
   - Question: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0007/question/
     ‚ùå Failed: Traceback (most recent call last):
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/sample_image2video.py", line 8, in <module>
    from hyvideo.config import parse_args
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/config.py", line 4, in <module>
    from .modules.models import HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/__init__.py", line 1, in <module>
    from .models import HYVideoDiffusionTransformer, HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/models.py", line 15, in <module>
    from .embed_layers import TimestepEmbedder, PatchEmbed, TextProjection
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/embed_layers.py", line 6, in <module>
    from ..utils.helpers import to_2tuple
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/utils/helpers.py", line 11, in <module>
    import deepspeed
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/__init__.py", line 9, in <module>
    from .runtime.engine import DeepSpeedEngine
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/engine.py", line 14, in <module>
    from deepspeed.runtime.zero.stage2 import FP16_DeepSpeedZeroOptimizer
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/zero/stage2.py", line 10, in <module>
    from torch._six import inf
ModuleNotFoundError: No module named 'torch._six'

      ‚ùå Failed: Traceback (most recent call last):
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/sample_image2video.py", line 8, in <module>
    from hyvideo.config import parse_args
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/config.py", line 4, in <module>
    from .modules.models import HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/__init__.py", line 1, in <module>
    from .models import HYVideoDiffusionTransformer, HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/models.py", line 15, in <module>
    from .embed_layers import TimestepEmbedder, PatchEmbed, TextProjection
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/embed_layers.py", line 6, in <module>
    from ..utils.helpers import to_2tuple
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/utils/helpers.py", line 11, in <module>
    import deepspeed
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/__init__.py", line 9, in <module>
    from .runtime.engine import DeepSpeedEngine
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/engine.py", line 14, in <module>
    from deepspeed.runtime.zero.stage2 import FP16_DeepSpeedZeroOptimizer
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/zero/stage2.py", line 10, in <module>
    from torch._six import inf
ModuleNotFoundError: No module named 'torch._six'

    [9/50] Processing: object_trajectory_0008

  üé¨ Generating: object_trajectory_0008 with hunyuan-video-i2v
     Image: /u/yli8/hokin/video-reason-experiments/data/questions/G-1_object_trajectory_data-generator/object_trajectory_task/object_trajectory_0008/first_frame.png
     Prompt: The scene contains a circle object and a dashed target position (indicated by a ...
Warning: HunyuanVideo requires 60-80GB GPU memory for 720p generation

‚úÖ Inference complete! Output saved to: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0008
   - Generated: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0008/video/video.mp4
   - Question: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0008/question/
     ‚ùå Failed: Traceback (most recent call last):
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/sample_image2video.py", line 8, in <module>
    from hyvideo.config import parse_args
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/config.py", line 4, in <module>
    from .modules.models import HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/__init__.py", line 1, in <module>
    from .models import HYVideoDiffusionTransformer, HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/models.py", line 15, in <module>
    from .embed_layers import TimestepEmbedder, PatchEmbed, TextProjection
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/embed_layers.py", line 6, in <module>
    from ..utils.helpers import to_2tuple
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/utils/helpers.py", line 11, in <module>
    import deepspeed
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/__init__.py", line 9, in <module>
    from .runtime.engine import DeepSpeedEngine
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/engine.py", line 14, in <module>
    from deepspeed.runtime.zero.stage2 import FP16_DeepSpeedZeroOptimizer
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/zero/stage2.py", line 10, in <module>
    from torch._six import inf
ModuleNotFoundError: No module named 'torch._six'

      ‚ùå Failed: Traceback (most recent call last):
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/sample_image2video.py", line 8, in <module>
    from hyvideo.config import parse_args
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/config.py", line 4, in <module>
    from .modules.models import HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/__init__.py", line 1, in <module>
    from .models import HYVideoDiffusionTransformer, HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/models.py", line 15, in <module>
    from .embed_layers import TimestepEmbedder, PatchEmbed, TextProjection
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/embed_layers.py", line 6, in <module>
    from ..utils.helpers import to_2tuple
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/utils/helpers.py", line 11, in <module>
    import deepspeed
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/__init__.py", line 9, in <module>
    from .runtime.engine import DeepSpeedEngine
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/engine.py", line 14, in <module>
    from deepspeed.runtime.zero.stage2 import FP16_DeepSpeedZeroOptimizer
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/zero/stage2.py", line 10, in <module>
    from torch._six import inf
ModuleNotFoundError: No module named 'torch._six'

    [10/50] Processing: object_trajectory_0009

  üé¨ Generating: object_trajectory_0009 with hunyuan-video-i2v
     Image: /u/yli8/hokin/video-reason-experiments/data/questions/G-1_object_trajectory_data-generator/object_trajectory_task/object_trajectory_0009/first_frame.png
     Prompt: The scene contains a square object and a dashed target position (indicated by a ...
Warning: HunyuanVideo requires 60-80GB GPU memory for 720p generation

‚úÖ Inference complete! Output saved to: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0009
   - Generated: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0009/video/video.mp4
   - Question: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0009/question/
     ‚ùå Failed: Traceback (most recent call last):
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/sample_image2video.py", line 8, in <module>
    from hyvideo.config import parse_args
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/config.py", line 4, in <module>
    from .modules.models import HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/__init__.py", line 1, in <module>
    from .models import HYVideoDiffusionTransformer, HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/models.py", line 15, in <module>
    from .embed_layers import TimestepEmbedder, PatchEmbed, TextProjection
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/embed_layers.py", line 6, in <module>
    from ..utils.helpers import to_2tuple
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/utils/helpers.py", line 11, in <module>
    import deepspeed
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/__init__.py", line 9, in <module>
    from .runtime.engine import DeepSpeedEngine
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/engine.py", line 14, in <module>
    from deepspeed.runtime.zero.stage2 import FP16_DeepSpeedZeroOptimizer
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/zero/stage2.py", line 10, in <module>
    from torch._six import inf
ModuleNotFoundError: No module named 'torch._six'

      ‚ùå Failed: Traceback (most recent call last):
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/sample_image2video.py", line 8, in <module>
    from hyvideo.config import parse_args
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/config.py", line 4, in <module>
    from .modules.models import HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/__init__.py", line 1, in <module>
    from .models import HYVideoDiffusionTransformer, HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/models.py", line 15, in <module>
    from .embed_layers import TimestepEmbedder, PatchEmbed, TextProjection
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/embed_layers.py", line 6, in <module>
    from ..utils.helpers import to_2tuple
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/utils/helpers.py", line 11, in <module>
    import deepspeed
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/__init__.py", line 9, in <module>
    from .runtime.engine import DeepSpeedEngine
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/engine.py", line 14, in <module>
    from deepspeed.runtime.zero.stage2 import FP16_DeepSpeedZeroOptimizer
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/zero/stage2.py", line 10, in <module>
    from torch._six import inf
ModuleNotFoundError: No module named 'torch._six'

    [11/50] Processing: object_trajectory_0010

  üé¨ Generating: object_trajectory_0010 with hunyuan-video-i2v
     Image: /u/yli8/hokin/video-reason-experiments/data/questions/G-1_object_trajectory_data-generator/object_trajectory_task/object_trajectory_0010/first_frame.png
     Prompt: The scene contains a circle object and a dashed target position (indicated by a ...
Warning: HunyuanVideo requires 60-80GB GPU memory for 720p generation

‚úÖ Inference complete! Output saved to: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0010
   - Generated: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0010/video/video.mp4
   - Question: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0010/question/
     ‚ùå Failed: Traceback (most recent call last):
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/sample_image2video.py", line 8, in <module>
    from hyvideo.config import parse_args
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/config.py", line 4, in <module>
    from .modules.models import HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/__init__.py", line 1, in <module>
    from .models import HYVideoDiffusionTransformer, HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/models.py", line 15, in <module>
    from .embed_layers import TimestepEmbedder, PatchEmbed, TextProjection
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/embed_layers.py", line 6, in <module>
    from ..utils.helpers import to_2tuple
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/utils/helpers.py", line 11, in <module>
    import deepspeed
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/__init__.py", line 9, in <module>
    from .runtime.engine import DeepSpeedEngine
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/engine.py", line 14, in <module>
    from deepspeed.runtime.zero.stage2 import FP16_DeepSpeedZeroOptimizer
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/zero/stage2.py", line 10, in <module>
    from torch._six import inf
ModuleNotFoundError: No module named 'torch._six'

      ‚ùå Failed: Traceback (most recent call last):
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/sample_image2video.py", line 8, in <module>
    from hyvideo.config import parse_args
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/config.py", line 4, in <module>
    from .modules.models import HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/__init__.py", line 1, in <module>
    from .models import HYVideoDiffusionTransformer, HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/models.py", line 15, in <module>
    from .embed_layers import TimestepEmbedder, PatchEmbed, TextProjection
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/embed_layers.py", line 6, in <module>
    from ..utils.helpers import to_2tuple
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/utils/helpers.py", line 11, in <module>
    import deepspeed
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/__init__.py", line 9, in <module>
    from .runtime.engine import DeepSpeedEngine
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/engine.py", line 14, in <module>
    from deepspeed.runtime.zero.stage2 import FP16_DeepSpeedZeroOptimizer
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/zero/stage2.py", line 10, in <module>
    from torch._six import inf
ModuleNotFoundError: No module named 'torch._six'

    [12/50] Processing: object_trajectory_0011

  üé¨ Generating: object_trajectory_0011 with hunyuan-video-i2v
     Image: /u/yli8/hokin/video-reason-experiments/data/questions/G-1_object_trajectory_data-generator/object_trajectory_task/object_trajectory_0011/first_frame.png
     Prompt: The scene contains a square object and a dashed target position (indicated by a ...
Warning: HunyuanVideo requires 60-80GB GPU memory for 720p generation

‚úÖ Inference complete! Output saved to: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0011
   - Generated: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0011/video/video.mp4
   - Question: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0011/question/
     ‚ùå Failed: Traceback (most recent call last):
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/sample_image2video.py", line 8, in <module>
    from hyvideo.config import parse_args
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/config.py", line 4, in <module>
    from .modules.models import HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/__init__.py", line 1, in <module>
    from .models import HYVideoDiffusionTransformer, HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/models.py", line 15, in <module>
    from .embed_layers import TimestepEmbedder, PatchEmbed, TextProjection
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/embed_layers.py", line 6, in <module>
    from ..utils.helpers import to_2tuple
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/utils/helpers.py", line 11, in <module>
    import deepspeed
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/__init__.py", line 9, in <module>
    from .runtime.engine import DeepSpeedEngine
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/engine.py", line 14, in <module>
    from deepspeed.runtime.zero.stage2 import FP16_DeepSpeedZeroOptimizer
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/zero/stage2.py", line 10, in <module>
    from torch._six import inf
ModuleNotFoundError: No module named 'torch._six'

      ‚ùå Failed: Traceback (most recent call last):
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/sample_image2video.py", line 8, in <module>
    from hyvideo.config import parse_args
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/config.py", line 4, in <module>
    from .modules.models import HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/__init__.py", line 1, in <module>
    from .models import HYVideoDiffusionTransformer, HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/models.py", line 15, in <module>
    from .embed_layers import TimestepEmbedder, PatchEmbed, TextProjection
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/embed_layers.py", line 6, in <module>
    from ..utils.helpers import to_2tuple
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/utils/helpers.py", line 11, in <module>
    import deepspeed
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/__init__.py", line 9, in <module>
    from .runtime.engine import DeepSpeedEngine
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/engine.py", line 14, in <module>
    from deepspeed.runtime.zero.stage2 import FP16_DeepSpeedZeroOptimizer
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/zero/stage2.py", line 10, in <module>
    from torch._six import inf
ModuleNotFoundError: No module named 'torch._six'

    [13/50] Processing: object_trajectory_0012

  üé¨ Generating: object_trajectory_0012 with hunyuan-video-i2v
     Image: /u/yli8/hokin/video-reason-experiments/data/questions/G-1_object_trajectory_data-generator/object_trajectory_task/object_trajectory_0012/first_frame.png
     Prompt: The scene contains a square object and a dashed target position (indicated by a ...
Warning: HunyuanVideo requires 60-80GB GPU memory for 720p generation

‚úÖ Inference complete! Output saved to: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0012
   - Generated: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0012/video/video.mp4
   - Question: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0012/question/
     ‚ùå Failed: Traceback (most recent call last):
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/sample_image2video.py", line 8, in <module>
    from hyvideo.config import parse_args
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/config.py", line 4, in <module>
    from .modules.models import HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/__init__.py", line 1, in <module>
    from .models import HYVideoDiffusionTransformer, HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/models.py", line 15, in <module>
    from .embed_layers import TimestepEmbedder, PatchEmbed, TextProjection
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/embed_layers.py", line 6, in <module>
    from ..utils.helpers import to_2tuple
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/utils/helpers.py", line 11, in <module>
    import deepspeed
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/__init__.py", line 9, in <module>
    from .runtime.engine import DeepSpeedEngine
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/engine.py", line 14, in <module>
    from deepspeed.runtime.zero.stage2 import FP16_DeepSpeedZeroOptimizer
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/zero/stage2.py", line 10, in <module>
    from torch._six import inf
ModuleNotFoundError: No module named 'torch._six'

      ‚ùå Failed: Traceback (most recent call last):
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/sample_image2video.py", line 8, in <module>
    from hyvideo.config import parse_args
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/config.py", line 4, in <module>
    from .modules.models import HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/__init__.py", line 1, in <module>
    from .models import HYVideoDiffusionTransformer, HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/models.py", line 15, in <module>
    from .embed_layers import TimestepEmbedder, PatchEmbed, TextProjection
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/embed_layers.py", line 6, in <module>
    from ..utils.helpers import to_2tuple
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/utils/helpers.py", line 11, in <module>
    import deepspeed
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/__init__.py", line 9, in <module>
    from .runtime.engine import DeepSpeedEngine
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/engine.py", line 14, in <module>
    from deepspeed.runtime.zero.stage2 import FP16_DeepSpeedZeroOptimizer
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/zero/stage2.py", line 10, in <module>
    from torch._six import inf
ModuleNotFoundError: No module named 'torch._six'

    [14/50] Processing: object_trajectory_0013

  üé¨ Generating: object_trajectory_0013 with hunyuan-video-i2v
     Image: /u/yli8/hokin/video-reason-experiments/data/questions/G-1_object_trajectory_data-generator/object_trajectory_task/object_trajectory_0013/first_frame.png
     Prompt: The scene contains a circle object and a dashed target position (indicated by a ...
Warning: HunyuanVideo requires 60-80GB GPU memory for 720p generation

‚úÖ Inference complete! Output saved to: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0013
   - Generated: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0013/video/video.mp4
   - Question: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0013/question/
     ‚ùå Failed: Traceback (most recent call last):
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/sample_image2video.py", line 8, in <module>
    from hyvideo.config import parse_args
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/config.py", line 4, in <module>
    from .modules.models import HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/__init__.py", line 1, in <module>
    from .models import HYVideoDiffusionTransformer, HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/models.py", line 15, in <module>
    from .embed_layers import TimestepEmbedder, PatchEmbed, TextProjection
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/embed_layers.py", line 6, in <module>
    from ..utils.helpers import to_2tuple
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/utils/helpers.py", line 11, in <module>
    import deepspeed
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/__init__.py", line 9, in <module>
    from .runtime.engine import DeepSpeedEngine
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/engine.py", line 14, in <module>
    from deepspeed.runtime.zero.stage2 import FP16_DeepSpeedZeroOptimizer
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/zero/stage2.py", line 10, in <module>
    from torch._six import inf
ModuleNotFoundError: No module named 'torch._six'

      ‚ùå Failed: Traceback (most recent call last):
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/sample_image2video.py", line 8, in <module>
    from hyvideo.config import parse_args
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/config.py", line 4, in <module>
    from .modules.models import HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/__init__.py", line 1, in <module>
    from .models import HYVideoDiffusionTransformer, HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/models.py", line 15, in <module>
    from .embed_layers import TimestepEmbedder, PatchEmbed, TextProjection
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/embed_layers.py", line 6, in <module>
    from ..utils.helpers import to_2tuple
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/utils/helpers.py", line 11, in <module>
    import deepspeed
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/__init__.py", line 9, in <module>
    from .runtime.engine import DeepSpeedEngine
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/engine.py", line 14, in <module>
    from deepspeed.runtime.zero.stage2 import FP16_DeepSpeedZeroOptimizer
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/zero/stage2.py", line 10, in <module>
    from torch._six import inf
ModuleNotFoundError: No module named 'torch._six'

    [15/50] Processing: object_trajectory_0014

  üé¨ Generating: object_trajectory_0014 with hunyuan-video-i2v
     Image: /u/yli8/hokin/video-reason-experiments/data/questions/G-1_object_trajectory_data-generator/object_trajectory_task/object_trajectory_0014/first_frame.png
     Prompt: The scene contains a circle object and a dashed target position (indicated by a ...
Warning: HunyuanVideo requires 60-80GB GPU memory for 720p generation

‚úÖ Inference complete! Output saved to: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0014
   - Generated: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0014/video/video.mp4
   - Question: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0014/question/
     ‚ùå Failed: Traceback (most recent call last):
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/sample_image2video.py", line 8, in <module>
    from hyvideo.config import parse_args
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/config.py", line 4, in <module>
    from .modules.models import HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/__init__.py", line 1, in <module>
    from .models import HYVideoDiffusionTransformer, HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/models.py", line 15, in <module>
    from .embed_layers import TimestepEmbedder, PatchEmbed, TextProjection
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/embed_layers.py", line 6, in <module>
    from ..utils.helpers import to_2tuple
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/utils/helpers.py", line 11, in <module>
    import deepspeed
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/__init__.py", line 9, in <module>
    from .runtime.engine import DeepSpeedEngine
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/engine.py", line 14, in <module>
    from deepspeed.runtime.zero.stage2 import FP16_DeepSpeedZeroOptimizer
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/zero/stage2.py", line 10, in <module>
    from torch._six import inf
ModuleNotFoundError: No module named 'torch._six'

      ‚ùå Failed: Traceback (most recent call last):
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/sample_image2video.py", line 8, in <module>
    from hyvideo.config import parse_args
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/config.py", line 4, in <module>
    from .modules.models import HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/__init__.py", line 1, in <module>
    from .models import HYVideoDiffusionTransformer, HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/models.py", line 15, in <module>
    from .embed_layers import TimestepEmbedder, PatchEmbed, TextProjection
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/embed_layers.py", line 6, in <module>
    from ..utils.helpers import to_2tuple
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/utils/helpers.py", line 11, in <module>
    import deepspeed
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/__init__.py", line 9, in <module>
    from .runtime.engine import DeepSpeedEngine
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/engine.py", line 14, in <module>
    from deepspeed.runtime.zero.stage2 import FP16_DeepSpeedZeroOptimizer
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/zero/stage2.py", line 10, in <module>
    from torch._six import inf
ModuleNotFoundError: No module named 'torch._six'

    [16/50] Processing: object_trajectory_0015

  üé¨ Generating: object_trajectory_0015 with hunyuan-video-i2v
     Image: /u/yli8/hokin/video-reason-experiments/data/questions/G-1_object_trajectory_data-generator/object_trajectory_task/object_trajectory_0015/first_frame.png
     Prompt: The scene contains a square object and a dashed target position (indicated by a ...
Warning: HunyuanVideo requires 60-80GB GPU memory for 720p generation

‚úÖ Inference complete! Output saved to: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0015
   - Generated: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0015/video/video.mp4
   - Question: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0015/question/
     ‚ùå Failed: Traceback (most recent call last):
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/sample_image2video.py", line 8, in <module>
    from hyvideo.config import parse_args
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/config.py", line 4, in <module>
    from .modules.models import HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/__init__.py", line 1, in <module>
    from .models import HYVideoDiffusionTransformer, HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/models.py", line 15, in <module>
    from .embed_layers import TimestepEmbedder, PatchEmbed, TextProjection
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/embed_layers.py", line 6, in <module>
    from ..utils.helpers import to_2tuple
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/utils/helpers.py", line 11, in <module>
    import deepspeed
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/__init__.py", line 9, in <module>
    from .runtime.engine import DeepSpeedEngine
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/engine.py", line 12, in <module>
    from tensorboardX import SummaryWriter
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/__init__.py", line 5, in <module>
    from .torchvis import TorchVis
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/torchvis.py", line 11, in <module>
    from .writer import SummaryWriter
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/writer.py", line 15, in <module>
    from .event_file_writer import EventFileWriter
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/event_file_writer.py", line 28, in <module>
    from .proto import event_pb2
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/proto/event_pb2.py", line 15, in <module>
    from tensorboardX.proto import summary_pb2 as tensorboardX_dot_proto_dot_summary__pb2
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/proto/summary_pb2.py", line 15, in <module>
    from tensorboardX.proto import tensor_pb2 as tensorboardX_dot_proto_dot_tensor__pb2
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/proto/tensor_pb2.py", line 15, in <module>
    from tensorboardX.proto import resource_handle_pb2 as tensorboardX_dot_proto_dot_resource__handle__pb2
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/proto/resource_handle_pb2.py", line 35, in <module>
    _descriptor.FieldDescriptor(
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/google/protobuf/descriptor.py", line 675, in __new__
    _message.Message._CheckCalledFromGeneratedFile()
TypeError: Descriptors cannot be created directly.
If this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.
If you cannot immediately regenerate your protos, some other possible workarounds are:
 1. Downgrade the protobuf package to 3.20.x or lower.
 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).

More information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates

      ‚ùå Failed: Traceback (most recent call last):
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/sample_image2video.py", line 8, in <module>
    from hyvideo.config import parse_args
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/config.py", line 4, in <module>
    from .modules.models import HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/__init__.py", line 1, in <module>
    from .models import HYVideoDiffusionTransformer, HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/models.py", line 15, in <module>
    from .embed_layers import TimestepEmbedder, PatchEmbed, TextProjection
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/embed_layers.py", line 6, in <module>
    from ..utils.helpers import to_2tuple
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/utils/helpers.py", line 11, in <module>
    import deepspeed
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/__init__.py", line 9, in <module>
    from .runtime.engine import DeepSpeedEngine
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/engine.py", line 12, in <module>
    from tensorboardX import SummaryWriter
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/__init__.py", line 5, in <module>
    from .torchvis import TorchVis
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/torchvis.py", line 11, in <module>
    from .writer import SummaryWriter
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/writer.py", line 15, in <module>
    from .event_file_writer import EventFileWriter
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/event_file_writer.py", line 28, in <module>
    from .proto import event_pb2
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/proto/event_pb2.py", line 15, in <module>
    from tensorboardX.proto import summary_pb2 as tensorboardX_dot_proto_dot_summary__pb2
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/proto/summary_pb2.py", line 15, in <module>
    from tensorboardX.proto import tensor_pb2 as tensorboardX_dot_proto_dot_tensor__pb2
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/proto/tensor_pb2.py", line 15, in <module>
    from tensorboardX.proto import resource_handle_pb2 as tensorboardX_dot_proto_dot_resource__handle__pb2
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/proto/resource_handle_pb2.py", line 35, in <module>
    _descriptor.FieldDescriptor(
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/google/protobuf/descriptor.py", line 675, in __new__
    _message.Message._CheckCalledFromGeneratedFile()
TypeError: Descriptors cannot be created directly.
If this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.
If you cannot immediately regenerate your protos, some other possible workarounds are:
 1. Downgrade the protobuf package to 3.20.x or lower.
 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).

More information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates

    [17/50] Processing: object_trajectory_0016

  üé¨ Generating: object_trajectory_0016 with hunyuan-video-i2v
     Image: /u/yli8/hokin/video-reason-experiments/data/questions/G-1_object_trajectory_data-generator/object_trajectory_task/object_trajectory_0016/first_frame.png
     Prompt: The scene contains a circle object and a dashed target position (indicated by a ...
Warning: HunyuanVideo requires 60-80GB GPU memory for 720p generation

‚úÖ Inference complete! Output saved to: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0016
   - Generated: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0016/video/video.mp4
   - Question: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0016/question/
     ‚ùå Failed: Traceback (most recent call last):
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/sample_image2video.py", line 8, in <module>
    from hyvideo.config import parse_args
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/config.py", line 4, in <module>
    from .modules.models import HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/__init__.py", line 1, in <module>
    from .models import HYVideoDiffusionTransformer, HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/models.py", line 15, in <module>
    from .embed_layers import TimestepEmbedder, PatchEmbed, TextProjection
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/embed_layers.py", line 6, in <module>
    from ..utils.helpers import to_2tuple
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/utils/helpers.py", line 11, in <module>
    import deepspeed
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/__init__.py", line 9, in <module>
    from .runtime.engine import DeepSpeedEngine
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/engine.py", line 12, in <module>
    from tensorboardX import SummaryWriter
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/__init__.py", line 5, in <module>
    from .torchvis import TorchVis
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/torchvis.py", line 11, in <module>
    from .writer import SummaryWriter
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/writer.py", line 15, in <module>
    from .event_file_writer import EventFileWriter
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/event_file_writer.py", line 28, in <module>
    from .proto import event_pb2
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/proto/event_pb2.py", line 15, in <module>
    from tensorboardX.proto import summary_pb2 as tensorboardX_dot_proto_dot_summary__pb2
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/proto/summary_pb2.py", line 15, in <module>
    from tensorboardX.proto import tensor_pb2 as tensorboardX_dot_proto_dot_tensor__pb2
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/proto/tensor_pb2.py", line 15, in <module>
    from tensorboardX.proto import resource_handle_pb2 as tensorboardX_dot_proto_dot_resource__handle__pb2
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/proto/resource_handle_pb2.py", line 35, in <module>
    _descriptor.FieldDescriptor(
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/google/protobuf/descriptor.py", line 675, in __new__
    _message.Message._CheckCalledFromGeneratedFile()
TypeError: Descriptors cannot be created directly.
If this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.
If you cannot immediately regenerate your protos, some other possible workarounds are:
 1. Downgrade the protobuf package to 3.20.x or lower.
 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).

More information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates

      ‚ùå Failed: Traceback (most recent call last):
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/sample_image2video.py", line 8, in <module>
    from hyvideo.config import parse_args
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/config.py", line 4, in <module>
    from .modules.models import HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/__init__.py", line 1, in <module>
    from .models import HYVideoDiffusionTransformer, HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/models.py", line 15, in <module>
    from .embed_layers import TimestepEmbedder, PatchEmbed, TextProjection
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/embed_layers.py", line 6, in <module>
    from ..utils.helpers import to_2tuple
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/utils/helpers.py", line 11, in <module>
    import deepspeed
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/__init__.py", line 9, in <module>
    from .runtime.engine import DeepSpeedEngine
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/engine.py", line 12, in <module>
    from tensorboardX import SummaryWriter
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/__init__.py", line 5, in <module>
    from .torchvis import TorchVis
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/torchvis.py", line 11, in <module>
    from .writer import SummaryWriter
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/writer.py", line 15, in <module>
    from .event_file_writer import EventFileWriter
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/event_file_writer.py", line 28, in <module>
    from .proto import event_pb2
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/proto/event_pb2.py", line 15, in <module>
    from tensorboardX.proto import summary_pb2 as tensorboardX_dot_proto_dot_summary__pb2
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/proto/summary_pb2.py", line 15, in <module>
    from tensorboardX.proto import tensor_pb2 as tensorboardX_dot_proto_dot_tensor__pb2
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/proto/tensor_pb2.py", line 15, in <module>
    from tensorboardX.proto import resource_handle_pb2 as tensorboardX_dot_proto_dot_resource__handle__pb2
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/proto/resource_handle_pb2.py", line 35, in <module>
    _descriptor.FieldDescriptor(
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/google/protobuf/descriptor.py", line 675, in __new__
    _message.Message._CheckCalledFromGeneratedFile()
TypeError: Descriptors cannot be created directly.
If this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.
If you cannot immediately regenerate your protos, some other possible workarounds are:
 1. Downgrade the protobuf package to 3.20.x or lower.
 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).

More information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates

    [18/50] Processing: object_trajectory_0017

  üé¨ Generating: object_trajectory_0017 with hunyuan-video-i2v
     Image: /u/yli8/hokin/video-reason-experiments/data/questions/G-1_object_trajectory_data-generator/object_trajectory_task/object_trajectory_0017/first_frame.png
     Prompt: The scene contains a triangle object and a dashed target position (indicated by ...
Warning: HunyuanVideo requires 60-80GB GPU memory for 720p generation

‚úÖ Inference complete! Output saved to: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0017
   - Generated: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0017/video/video.mp4
   - Question: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0017/question/
     ‚ùå Failed: Traceback (most recent call last):
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/sample_image2video.py", line 8, in <module>
    from hyvideo.config import parse_args
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/config.py", line 4, in <module>
    from .modules.models import HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/__init__.py", line 1, in <module>
    from .models import HYVideoDiffusionTransformer, HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/models.py", line 15, in <module>
    from .embed_layers import TimestepEmbedder, PatchEmbed, TextProjection
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/embed_layers.py", line 6, in <module>
    from ..utils.helpers import to_2tuple
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/utils/helpers.py", line 11, in <module>
    import deepspeed
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/__init__.py", line 9, in <module>
    from .runtime.engine import DeepSpeedEngine
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/engine.py", line 12, in <module>
    from tensorboardX import SummaryWriter
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/__init__.py", line 5, in <module>
    from .torchvis import TorchVis
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/torchvis.py", line 11, in <module>
    from .writer import SummaryWriter
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/writer.py", line 15, in <module>
    from .event_file_writer import EventFileWriter
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/event_file_writer.py", line 28, in <module>
    from .proto import event_pb2
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/proto/event_pb2.py", line 15, in <module>
    from tensorboardX.proto import summary_pb2 as tensorboardX_dot_proto_dot_summary__pb2
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/proto/summary_pb2.py", line 15, in <module>
    from tensorboardX.proto import tensor_pb2 as tensorboardX_dot_proto_dot_tensor__pb2
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/proto/tensor_pb2.py", line 15, in <module>
    from tensorboardX.proto import resource_handle_pb2 as tensorboardX_dot_proto_dot_resource__handle__pb2
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/proto/resource_handle_pb2.py", line 35, in <module>
    _descriptor.FieldDescriptor(
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/google/protobuf/descriptor.py", line 675, in __new__
    _message.Message._CheckCalledFromGeneratedFile()
TypeError: Descriptors cannot be created directly.
If this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.
If you cannot immediately regenerate your protos, some other possible workarounds are:
 1. Downgrade the protobuf package to 3.20.x or lower.
 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).

More information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates

      ‚ùå Failed: Traceback (most recent call last):
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/sample_image2video.py", line 8, in <module>
    from hyvideo.config import parse_args
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/config.py", line 4, in <module>
    from .modules.models import HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/__init__.py", line 1, in <module>
    from .models import HYVideoDiffusionTransformer, HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/models.py", line 15, in <module>
    from .embed_layers import TimestepEmbedder, PatchEmbed, TextProjection
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/embed_layers.py", line 6, in <module>
    from ..utils.helpers import to_2tuple
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/utils/helpers.py", line 11, in <module>
    import deepspeed
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/__init__.py", line 9, in <module>
    from .runtime.engine import DeepSpeedEngine
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/engine.py", line 12, in <module>
    from tensorboardX import SummaryWriter
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/__init__.py", line 5, in <module>
    from .torchvis import TorchVis
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/torchvis.py", line 11, in <module>
    from .writer import SummaryWriter
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/writer.py", line 15, in <module>
    from .event_file_writer import EventFileWriter
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/event_file_writer.py", line 28, in <module>
    from .proto import event_pb2
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/proto/event_pb2.py", line 15, in <module>
    from tensorboardX.proto import summary_pb2 as tensorboardX_dot_proto_dot_summary__pb2
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/proto/summary_pb2.py", line 15, in <module>
    from tensorboardX.proto import tensor_pb2 as tensorboardX_dot_proto_dot_tensor__pb2
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/proto/tensor_pb2.py", line 15, in <module>
    from tensorboardX.proto import resource_handle_pb2 as tensorboardX_dot_proto_dot_resource__handle__pb2
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/proto/resource_handle_pb2.py", line 35, in <module>
    _descriptor.FieldDescriptor(
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/google/protobuf/descriptor.py", line 675, in __new__
    _message.Message._CheckCalledFromGeneratedFile()
TypeError: Descriptors cannot be created directly.
If this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.
If you cannot immediately regenerate your protos, some other possible workarounds are:
 1. Downgrade the protobuf package to 3.20.x or lower.
 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).

More information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates

    [19/50] Processing: object_trajectory_0018

  üé¨ Generating: object_trajectory_0018 with hunyuan-video-i2v
     Image: /u/yli8/hokin/video-reason-experiments/data/questions/G-1_object_trajectory_data-generator/object_trajectory_task/object_trajectory_0018/first_frame.png
     Prompt: The scene contains a circle object and a dashed target position (indicated by a ...
Warning: HunyuanVideo requires 60-80GB GPU memory for 720p generation

‚úÖ Inference complete! Output saved to: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0018
   - Generated: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0018/video/video.mp4
   - Question: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0018/question/
     ‚ùå Failed: Traceback (most recent call last):
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/sample_image2video.py", line 8, in <module>
    from hyvideo.config import parse_args
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/config.py", line 4, in <module>
    from .modules.models import HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/__init__.py", line 1, in <module>
    from .models import HYVideoDiffusionTransformer, HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/models.py", line 15, in <module>
    from .embed_layers import TimestepEmbedder, PatchEmbed, TextProjection
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/embed_layers.py", line 6, in <module>
    from ..utils.helpers import to_2tuple
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/utils/helpers.py", line 11, in <module>
    import deepspeed
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/__init__.py", line 9, in <module>
    from .runtime.engine import DeepSpeedEngine
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/engine.py", line 12, in <module>
    from tensorboardX import SummaryWriter
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/__init__.py", line 5, in <module>
    from .torchvis import TorchVis
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/torchvis.py", line 11, in <module>
    from .writer import SummaryWriter
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/writer.py", line 15, in <module>
    from .event_file_writer import EventFileWriter
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/event_file_writer.py", line 28, in <module>
    from .proto import event_pb2
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/proto/event_pb2.py", line 15, in <module>
    from tensorboardX.proto import summary_pb2 as tensorboardX_dot_proto_dot_summary__pb2
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/proto/summary_pb2.py", line 15, in <module>
    from tensorboardX.proto import tensor_pb2 as tensorboardX_dot_proto_dot_tensor__pb2
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/proto/tensor_pb2.py", line 15, in <module>
    from tensorboardX.proto import resource_handle_pb2 as tensorboardX_dot_proto_dot_resource__handle__pb2
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/proto/resource_handle_pb2.py", line 35, in <module>
    _descriptor.FieldDescriptor(
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/google/protobuf/descriptor.py", line 675, in __new__
    _message.Message._CheckCalledFromGeneratedFile()
TypeError: Descriptors cannot be created directly.
If this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.
If you cannot immediately regenerate your protos, some other possible workarounds are:
 1. Downgrade the protobuf package to 3.20.x or lower.
 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).

More information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates

      ‚ùå Failed: Traceback (most recent call last):
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/sample_image2video.py", line 8, in <module>
    from hyvideo.config import parse_args
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/config.py", line 4, in <module>
    from .modules.models import HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/__init__.py", line 1, in <module>
    from .models import HYVideoDiffusionTransformer, HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/models.py", line 15, in <module>
    from .embed_layers import TimestepEmbedder, PatchEmbed, TextProjection
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/embed_layers.py", line 6, in <module>
    from ..utils.helpers import to_2tuple
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/utils/helpers.py", line 11, in <module>
    import deepspeed
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/__init__.py", line 9, in <module>
    from .runtime.engine import DeepSpeedEngine
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/engine.py", line 12, in <module>
    from tensorboardX import SummaryWriter
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/__init__.py", line 5, in <module>
    from .torchvis import TorchVis
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/torchvis.py", line 11, in <module>
    from .writer import SummaryWriter
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/writer.py", line 15, in <module>
    from .event_file_writer import EventFileWriter
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/event_file_writer.py", line 28, in <module>
    from .proto import event_pb2
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/proto/event_pb2.py", line 15, in <module>
    from tensorboardX.proto import summary_pb2 as tensorboardX_dot_proto_dot_summary__pb2
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/proto/summary_pb2.py", line 15, in <module>
    from tensorboardX.proto import tensor_pb2 as tensorboardX_dot_proto_dot_tensor__pb2
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/proto/tensor_pb2.py", line 15, in <module>
    from tensorboardX.proto import resource_handle_pb2 as tensorboardX_dot_proto_dot_resource__handle__pb2
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/proto/resource_handle_pb2.py", line 35, in <module>
    _descriptor.FieldDescriptor(
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/google/protobuf/descriptor.py", line 675, in __new__
    _message.Message._CheckCalledFromGeneratedFile()
TypeError: Descriptors cannot be created directly.
If this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.
If you cannot immediately regenerate your protos, some other possible workarounds are:
 1. Downgrade the protobuf package to 3.20.x or lower.
 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).

More information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates

    [20/50] Processing: object_trajectory_0019

  üé¨ Generating: object_trajectory_0019 with hunyuan-video-i2v
     Image: /u/yli8/hokin/video-reason-experiments/data/questions/G-1_object_trajectory_data-generator/object_trajectory_task/object_trajectory_0019/first_frame.png
     Prompt: The scene contains a triangle object and a dashed target position (indicated by ...
Warning: HunyuanVideo requires 60-80GB GPU memory for 720p generation

‚úÖ Inference complete! Output saved to: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0019
   - Generated: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0019/video/video.mp4
   - Question: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0019/question/
     ‚ùå Failed: Traceback (most recent call last):
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/sample_image2video.py", line 8, in <module>
    from hyvideo.config import parse_args
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/config.py", line 4, in <module>
    from .modules.models import HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/__init__.py", line 1, in <module>
    from .models import HYVideoDiffusionTransformer, HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/models.py", line 15, in <module>
    from .embed_layers import TimestepEmbedder, PatchEmbed, TextProjection
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/embed_layers.py", line 6, in <module>
    from ..utils.helpers import to_2tuple
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/utils/helpers.py", line 11, in <module>
    import deepspeed
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/__init__.py", line 9, in <module>
    from .runtime.engine import DeepSpeedEngine
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/engine.py", line 12, in <module>
    from tensorboardX import SummaryWriter
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/__init__.py", line 5, in <module>
    from .torchvis import TorchVis
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/torchvis.py", line 11, in <module>
    from .writer import SummaryWriter
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/writer.py", line 15, in <module>
    from .event_file_writer import EventFileWriter
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/event_file_writer.py", line 28, in <module>
    from .proto import event_pb2
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/proto/event_pb2.py", line 15, in <module>
    from tensorboardX.proto import summary_pb2 as tensorboardX_dot_proto_dot_summary__pb2
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/proto/summary_pb2.py", line 15, in <module>
    from tensorboardX.proto import tensor_pb2 as tensorboardX_dot_proto_dot_tensor__pb2
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/proto/tensor_pb2.py", line 15, in <module>
    from tensorboardX.proto import resource_handle_pb2 as tensorboardX_dot_proto_dot_resource__handle__pb2
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/proto/resource_handle_pb2.py", line 35, in <module>
    _descriptor.FieldDescriptor(
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/google/protobuf/descriptor.py", line 675, in __new__
    _message.Message._CheckCalledFromGeneratedFile()
TypeError: Descriptors cannot be created directly.
If this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.
If you cannot immediately regenerate your protos, some other possible workarounds are:
 1. Downgrade the protobuf package to 3.20.x or lower.
 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).

More information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates

      ‚ùå Failed: Traceback (most recent call last):
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/sample_image2video.py", line 8, in <module>
    from hyvideo.config import parse_args
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/config.py", line 4, in <module>
    from .modules.models import HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/__init__.py", line 1, in <module>
    from .models import HYVideoDiffusionTransformer, HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/models.py", line 15, in <module>
    from .embed_layers import TimestepEmbedder, PatchEmbed, TextProjection
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/embed_layers.py", line 6, in <module>
    from ..utils.helpers import to_2tuple
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/utils/helpers.py", line 11, in <module>
    import deepspeed
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/__init__.py", line 9, in <module>
    from .runtime.engine import DeepSpeedEngine
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/engine.py", line 12, in <module>
    from tensorboardX import SummaryWriter
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/__init__.py", line 5, in <module>
    from .torchvis import TorchVis
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/torchvis.py", line 11, in <module>
    from .writer import SummaryWriter
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/writer.py", line 15, in <module>
    from .event_file_writer import EventFileWriter
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/event_file_writer.py", line 28, in <module>
    from .proto import event_pb2
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/proto/event_pb2.py", line 15, in <module>
    from tensorboardX.proto import summary_pb2 as tensorboardX_dot_proto_dot_summary__pb2
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/proto/summary_pb2.py", line 15, in <module>
    from tensorboardX.proto import tensor_pb2 as tensorboardX_dot_proto_dot_tensor__pb2
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/proto/tensor_pb2.py", line 15, in <module>
    from tensorboardX.proto import resource_handle_pb2 as tensorboardX_dot_proto_dot_resource__handle__pb2
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/proto/resource_handle_pb2.py", line 35, in <module>
    _descriptor.FieldDescriptor(
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/google/protobuf/descriptor.py", line 675, in __new__
    _message.Message._CheckCalledFromGeneratedFile()
TypeError: Descriptors cannot be created directly.
If this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.
If you cannot immediately regenerate your protos, some other possible workarounds are:
 1. Downgrade the protobuf package to 3.20.x or lower.
 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).

More information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates

    [21/50] Processing: object_trajectory_0020

  üé¨ Generating: object_trajectory_0020 with hunyuan-video-i2v
     Image: /u/yli8/hokin/video-reason-experiments/data/questions/G-1_object_trajectory_data-generator/object_trajectory_task/object_trajectory_0020/first_frame.png
     Prompt: The scene contains a circle object and a dashed target position (indicated by a ...
Warning: HunyuanVideo requires 60-80GB GPU memory for 720p generation

‚úÖ Inference complete! Output saved to: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0020
   - Generated: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0020/video/video.mp4
   - Question: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0020/question/
     ‚ùå Failed: Traceback (most recent call last):
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/sample_image2video.py", line 8, in <module>
    from hyvideo.config import parse_args
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/config.py", line 4, in <module>
    from .modules.models import HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/__init__.py", line 1, in <module>
    from .models import HYVideoDiffusionTransformer, HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/models.py", line 15, in <module>
    from .embed_layers import TimestepEmbedder, PatchEmbed, TextProjection
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/embed_layers.py", line 6, in <module>
    from ..utils.helpers import to_2tuple
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/utils/helpers.py", line 11, in <module>
    import deepspeed
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/__init__.py", line 9, in <module>
    from .runtime.engine import DeepSpeedEngine
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/engine.py", line 12, in <module>
    from tensorboardX import SummaryWriter
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/__init__.py", line 5, in <module>
    from .torchvis import TorchVis
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/torchvis.py", line 11, in <module>
    from .writer import SummaryWriter
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/writer.py", line 15, in <module>
    from .event_file_writer import EventFileWriter
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/event_file_writer.py", line 28, in <module>
    from .proto import event_pb2
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/proto/event_pb2.py", line 15, in <module>
    from tensorboardX.proto import summary_pb2 as tensorboardX_dot_proto_dot_summary__pb2
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/proto/summary_pb2.py", line 15, in <module>
    from tensorboardX.proto import tensor_pb2 as tensorboardX_dot_proto_dot_tensor__pb2
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/proto/tensor_pb2.py", line 15, in <module>
    from tensorboardX.proto import resource_handle_pb2 as tensorboardX_dot_proto_dot_resource__handle__pb2
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/proto/resource_handle_pb2.py", line 35, in <module>
    _descriptor.FieldDescriptor(
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/google/protobuf/descriptor.py", line 675, in __new__
    _message.Message._CheckCalledFromGeneratedFile()
TypeError: Descriptors cannot be created directly.
If this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.
If you cannot immediately regenerate your protos, some other possible workarounds are:
 1. Downgrade the protobuf package to 3.20.x or lower.
 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).

More information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates

      ‚ùå Failed: Traceback (most recent call last):
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/sample_image2video.py", line 8, in <module>
    from hyvideo.config import parse_args
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/config.py", line 4, in <module>
    from .modules.models import HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/__init__.py", line 1, in <module>
    from .models import HYVideoDiffusionTransformer, HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/models.py", line 15, in <module>
    from .embed_layers import TimestepEmbedder, PatchEmbed, TextProjection
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/embed_layers.py", line 6, in <module>
    from ..utils.helpers import to_2tuple
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/utils/helpers.py", line 11, in <module>
    import deepspeed
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/__init__.py", line 9, in <module>
    from .runtime.engine import DeepSpeedEngine
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/engine.py", line 12, in <module>
    from tensorboardX import SummaryWriter
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/__init__.py", line 5, in <module>
    from .torchvis import TorchVis
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/torchvis.py", line 11, in <module>
    from .writer import SummaryWriter
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/writer.py", line 15, in <module>
    from .event_file_writer import EventFileWriter
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/event_file_writer.py", line 28, in <module>
    from .proto import event_pb2
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/proto/event_pb2.py", line 15, in <module>
    from tensorboardX.proto import summary_pb2 as tensorboardX_dot_proto_dot_summary__pb2
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/proto/summary_pb2.py", line 15, in <module>
    from tensorboardX.proto import tensor_pb2 as tensorboardX_dot_proto_dot_tensor__pb2
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/proto/tensor_pb2.py", line 15, in <module>
    from tensorboardX.proto import resource_handle_pb2 as tensorboardX_dot_proto_dot_resource__handle__pb2
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/tensorboardX/proto/resource_handle_pb2.py", line 35, in <module>
    _descriptor.FieldDescriptor(
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/google/protobuf/descriptor.py", line 675, in __new__
    _message.Message._CheckCalledFromGeneratedFile()
TypeError: Descriptors cannot be created directly.
If this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.
If you cannot immediately regenerate your protos, some other possible workarounds are:
 1. Downgrade the protobuf package to 3.20.x or lower.
 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).

More information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates

    [22/50] Processing: object_trajectory_0021

  üé¨ Generating: object_trajectory_0021 with hunyuan-video-i2v
     Image: /u/yli8/hokin/video-reason-experiments/data/questions/G-1_object_trajectory_data-generator/object_trajectory_task/object_trajectory_0021/first_frame.png
     Prompt: The scene contains a circle object and a dashed target position (indicated by a ...
Warning: HunyuanVideo requires 60-80GB GPU memory for 720p generation

‚úÖ Inference complete! Output saved to: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0021
   - Generated: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0021/video/video.mp4
   - Question: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0021/question/
     ‚ùå Failed: Traceback (most recent call last):
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/sample_image2video.py", line 8, in <module>
    from hyvideo.config import parse_args
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/config.py", line 4, in <module>
    from .modules.models import HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/__init__.py", line 1, in <module>
    from .models import HYVideoDiffusionTransformer, HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/models.py", line 15, in <module>
    from .embed_layers import TimestepEmbedder, PatchEmbed, TextProjection
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/embed_layers.py", line 6, in <module>
    from ..utils.helpers import to_2tuple
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/utils/helpers.py", line 11, in <module>
    import deepspeed
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/__init__.py", line 9, in <module>
    from .runtime.engine import DeepSpeedEngine
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/engine.py", line 14, in <module>
    from deepspeed.runtime.zero.stage2 import FP16_DeepSpeedZeroOptimizer
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/zero/stage2.py", line 10, in <module>
    from torch._six import inf
ModuleNotFoundError: No module named 'torch._six'

      ‚ùå Failed: Traceback (most recent call last):
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/sample_image2video.py", line 8, in <module>
    from hyvideo.config import parse_args
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/config.py", line 4, in <module>
    from .modules.models import HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/__init__.py", line 1, in <module>
    from .models import HYVideoDiffusionTransformer, HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/models.py", line 15, in <module>
    from .embed_layers import TimestepEmbedder, PatchEmbed, TextProjection
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/embed_layers.py", line 6, in <module>
    from ..utils.helpers import to_2tuple
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/utils/helpers.py", line 11, in <module>
    import deepspeed
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/__init__.py", line 9, in <module>
    from .runtime.engine import DeepSpeedEngine
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/engine.py", line 14, in <module>
    from deepspeed.runtime.zero.stage2 import FP16_DeepSpeedZeroOptimizer
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/zero/stage2.py", line 10, in <module>
    from torch._six import inf
ModuleNotFoundError: No module named 'torch._six'

    [23/50] Processing: object_trajectory_0022

  üé¨ Generating: object_trajectory_0022 with hunyuan-video-i2v
     Image: /u/yli8/hokin/video-reason-experiments/data/questions/G-1_object_trajectory_data-generator/object_trajectory_task/object_trajectory_0022/first_frame.png
     Prompt: The scene contains a triangle object and a dashed target position (indicated by ...
Warning: HunyuanVideo requires 60-80GB GPU memory for 720p generation

‚úÖ Inference complete! Output saved to: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0022
   - Generated: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0022/video/video.mp4
   - Question: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0022/question/
     ‚ùå Failed: Traceback (most recent call last):
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/sample_image2video.py", line 8, in <module>
    from hyvideo.config import parse_args
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/config.py", line 4, in <module>
    from .modules.models import HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/__init__.py", line 1, in <module>
    from .models import HYVideoDiffusionTransformer, HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/models.py", line 15, in <module>
    from .embed_layers import TimestepEmbedder, PatchEmbed, TextProjection
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/embed_layers.py", line 6, in <module>
    from ..utils.helpers import to_2tuple
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/utils/helpers.py", line 11, in <module>
    import deepspeed
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/__init__.py", line 9, in <module>
    from .runtime.engine import DeepSpeedEngine
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/engine.py", line 14, in <module>
    from deepspeed.runtime.zero.stage2 import FP16_DeepSpeedZeroOptimizer
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/zero/stage2.py", line 10, in <module>
    from torch._six import inf
ModuleNotFoundError: No module named 'torch._six'

      ‚ùå Failed: Traceback (most recent call last):
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/sample_image2video.py", line 8, in <module>
    from hyvideo.config import parse_args
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/config.py", line 4, in <module>
    from .modules.models import HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/__init__.py", line 1, in <module>
    from .models import HYVideoDiffusionTransformer, HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/models.py", line 15, in <module>
    from .embed_layers import TimestepEmbedder, PatchEmbed, TextProjection
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/embed_layers.py", line 6, in <module>
    from ..utils.helpers import to_2tuple
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/utils/helpers.py", line 11, in <module>
    import deepspeed
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/__init__.py", line 9, in <module>
    from .runtime.engine import DeepSpeedEngine
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/engine.py", line 14, in <module>
    from deepspeed.runtime.zero.stage2 import FP16_DeepSpeedZeroOptimizer
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/zero/stage2.py", line 10, in <module>
    from torch._six import inf
ModuleNotFoundError: No module named 'torch._six'

    [24/50] Processing: object_trajectory_0023

  üé¨ Generating: object_trajectory_0023 with hunyuan-video-i2v
     Image: /u/yli8/hokin/video-reason-experiments/data/questions/G-1_object_trajectory_data-generator/object_trajectory_task/object_trajectory_0023/first_frame.png
     Prompt: The scene contains a diamond object and a dashed target position (indicated by a...
Warning: HunyuanVideo requires 60-80GB GPU memory for 720p generation

‚úÖ Inference complete! Output saved to: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0023
   - Generated: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0023/video/video.mp4
   - Question: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0023/question/
     ‚ùå Failed: Traceback (most recent call last):
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/sample_image2video.py", line 8, in <module>
    from hyvideo.config import parse_args
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/config.py", line 4, in <module>
    from .modules.models import HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/__init__.py", line 1, in <module>
    from .models import HYVideoDiffusionTransformer, HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/models.py", line 15, in <module>
    from .embed_layers import TimestepEmbedder, PatchEmbed, TextProjection
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/embed_layers.py", line 6, in <module>
    from ..utils.helpers import to_2tuple
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/utils/helpers.py", line 11, in <module>
    import deepspeed
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/__init__.py", line 9, in <module>
    from .runtime.engine import DeepSpeedEngine
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/engine.py", line 14, in <module>
    from deepspeed.runtime.zero.stage2 import FP16_DeepSpeedZeroOptimizer
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/zero/stage2.py", line 10, in <module>
    from torch._six import inf
ModuleNotFoundError: No module named 'torch._six'

      ‚ùå Failed: Traceback (most recent call last):
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/sample_image2video.py", line 8, in <module>
    from hyvideo.config import parse_args
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/config.py", line 4, in <module>
    from .modules.models import HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/__init__.py", line 1, in <module>
    from .models import HYVideoDiffusionTransformer, HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/models.py", line 15, in <module>
    from .embed_layers import TimestepEmbedder, PatchEmbed, TextProjection
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/embed_layers.py", line 6, in <module>
    from ..utils.helpers import to_2tuple
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/utils/helpers.py", line 11, in <module>
    import deepspeed
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/__init__.py", line 9, in <module>
    from .runtime.engine import DeepSpeedEngine
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/engine.py", line 14, in <module>
    from deepspeed.runtime.zero.stage2 import FP16_DeepSpeedZeroOptimizer
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/zero/stage2.py", line 10, in <module>
    from torch._six import inf
ModuleNotFoundError: No module named 'torch._six'

    [25/50] Processing: object_trajectory_0024

  üé¨ Generating: object_trajectory_0024 with hunyuan-video-i2v
     Image: /u/yli8/hokin/video-reason-experiments/data/questions/G-1_object_trajectory_data-generator/object_trajectory_task/object_trajectory_0024/first_frame.png
     Prompt: The scene contains a circle object and a dashed target position (indicated by a ...
Warning: HunyuanVideo requires 60-80GB GPU memory for 720p generation

‚úÖ Inference complete! Output saved to: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0024
   - Generated: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0024/video/video.mp4
   - Question: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0024/question/
     ‚ùå Failed: Traceback (most recent call last):
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/sample_image2video.py", line 8, in <module>
    from hyvideo.config import parse_args
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/config.py", line 4, in <module>
    from .modules.models import HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/__init__.py", line 1, in <module>
    from .models import HYVideoDiffusionTransformer, HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/models.py", line 15, in <module>
    from .embed_layers import TimestepEmbedder, PatchEmbed, TextProjection
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/embed_layers.py", line 6, in <module>
    from ..utils.helpers import to_2tuple
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/utils/helpers.py", line 11, in <module>
    import deepspeed
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/__init__.py", line 9, in <module>
    from .runtime.engine import DeepSpeedEngine
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/engine.py", line 14, in <module>
    from deepspeed.runtime.zero.stage2 import FP16_DeepSpeedZeroOptimizer
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/zero/stage2.py", line 10, in <module>
    from torch._six import inf
ModuleNotFoundError: No module named 'torch._six'

      ‚ùå Failed: Traceback (most recent call last):
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/sample_image2video.py", line 8, in <module>
    from hyvideo.config import parse_args
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/config.py", line 4, in <module>
    from .modules.models import HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/__init__.py", line 1, in <module>
    from .models import HYVideoDiffusionTransformer, HUNYUAN_VIDEO_CONFIG
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/models.py", line 15, in <module>
    from .embed_layers import TimestepEmbedder, PatchEmbed, TextProjection
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/embed_layers.py", line 6, in <module>
    from ..utils.helpers import to_2tuple
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/utils/helpers.py", line 11, in <module>
    import deepspeed
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/__init__.py", line 9, in <module>
    from .runtime.engine import DeepSpeedEngine
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/engine.py", line 14, in <module>
    from deepspeed.runtime.zero.stage2 import FP16_DeepSpeedZeroOptimizer
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.12/site-packages/deepspeed/runtime/zero/stage2.py", line 10, in <module>
    from torch._six import inf
ModuleNotFoundError: No module named 'torch._six'

    [26/50] Processing: object_trajectory_0025

  üé¨ Generating: object_trajectory_0025 with hunyuan-video-i2v
     Image: /u/yli8/hokin/video-reason-experiments/data/questions/G-1_object_trajectory_data-generator/object_trajectory_task/object_trajectory_0025/first_frame.png
     Prompt: The scene contains a diamond object and a dashed target position (indicated by a...
Warning: HunyuanVideo requires 60-80GB GPU memory for 720p generation

‚úÖ Inference complete! Output saved to: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0025
   - Generated: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0025/video/video.mp4
   - Question: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0025/question/
     ‚ùå Failed: 2026-01-11 18:52:31.653 | INFO     | hyvideo.inference:from_pretrained:220 - Got text-to-video model root path: /u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/ckpts/hunyuan-video-i2v-720p
2026-01-11 18:52:32.497 | INFO     | hyvideo.inference:from_pretrained:258 - Building model...
2026-01-11 18:52:33.500 | INFO     | hyvideo.inference:load_state_dict:494 - Loading torch model ckpts/hunyuan-video-i2v-720p/transformers/mp_rank_00_model_states.pt...
2026-01-11 18:52:55.199 | INFO     | hyvideo.vae:load_vae:29 - Loading 3D VAE model (884-16c-hy) from: /u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/ckpts/hunyuan-video-i2v-720p/vae
2026-01-11 18:52:56.978 | INFO     | hyvideo.vae:load_vae:55 - VAE to dtype: torch.float16
2026-01-11 18:52:56.988 | INFO     | hyvideo.text_encoder:load_text_encoder:35 - Loading text encoder model (llm-i2v) from: /u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/ckpts/text_encoder_i2v

Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
Loading checkpoint shards:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:11<00:33, 11.27s/it]
Loading checkpoint shards:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:13<00:12,  6.17s/it]
Loading checkpoint shards:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:16<00:04,  4.58s/it]
Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:45<00:00, 14.28s/it]
Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:45<00:00, 11.43s/it]
2026-01-11 18:53:44.599 | INFO     | hyvideo.text_encoder:load_text_encoder:61 - Text encoder to dtype: torch.float16
2026-01-11 18:53:44.603 | INFO     | hyvideo.text_encoder:load_tokenizer:75 - Loading tokenizer (llm-i2v) from: /u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/ckpts/text_encoder_i2v
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2026-01-11 18:53:44.838 | INFO     | hyvideo.text_encoder:load_text_encoder:35 - Loading text encoder model (clipL) from: /u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/ckpts/text_encoder_2
2026-01-11 18:53:46.298 | INFO     | hyvideo.text_encoder:load_text_encoder:61 - Text encoder to dtype: torch.float16
2026-01-11 18:53:46.299 | INFO     | hyvideo.text_encoder:load_tokenizer:75 - Loading tokenizer (clipL) from: /u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/ckpts/text_encoder_2
2026-01-11 18:53:46.529 | INFO     | hyvideo.inference:predict:771 - Input (height, width, video_length) = (1280, 720, 129)
2026-01-11 18:53:48.635 | DEBUG    | hyvideo.inference:get_rotary_pos_embed:690 - actual_num_frames = 129 <= 192, using original RoPE
2026-01-11 18:53:48.671 | DEBUG    | hyvideo.inference:get_rotary_pos_embed:698 - freqs_cos shape: torch.Size([118800, 128]), device: cpu
2026-01-11 18:53:48.671 | DEBUG    | hyvideo.inference:predict:886 - 
                        height: 960
                         width: 960
                  video_length: 129
                        prompt: ['The scene contains a diamond object and a dashed target position (indicated by a dashed outline of the same shape). Keep the dashed target position unchanged. Move the diamond object to the dashed target position along the shortest path, ensuring it completely overlaps with the target.']
                    neg_prompt: ['']
                          seed: 0
                   infer_steps: 50
         num_videos_per_prompt: 1
                guidance_scale: 1.0
                      n_tokens: 118800
                    flow_shift: 7.0
       embedded_guidance_scale: 6.0
                 i2v_stability: True

  0%|          | 0/50 [00:00<?, ?it/s]
  0%|          | 0/50 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/sample_image2video.py", line 65, in <module>
    main()
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/sample_image2video.py", line 32, in main
    outputs = hunyuan_video_sampler.predict(
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/sw/user/python/miniforge3-pytorch-24.11.3/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/inference.py", line 889, in predict
    samples = self.pipeline(
              ^^^^^^^^^^^^^^
  File "/sw/user/python/miniforge3-pytorch-24.11.3/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/diffusion/pipelines/pipeline_hunyuan_video.py", line 1048, in __call__
    noise_pred = self.transformer(  # For an input image (129, 192, 336) (1, 256, 256)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/sw/user/python/miniforge3-pytorch-24.11.3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/sw/user/python/miniforge3-pytorch-24.11.3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/models.py", line 763, in forward
    img, txt = block(*double_block_args)
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/sw/user/python/miniforge3-pytorch-24.11.3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/sw/user/python/miniforge3-pytorch-24.11.3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/models.py", line 233, in forward
    attn = attention(
           ^^^^^^^^^^
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/attenion.py", line 108, in attention
    x = flash_attn_varlen_func(
        ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: 'NoneType' object is not callable

      ‚ùå Failed: 2026-01-11 18:52:31.653 | INFO     | hyvideo.inference:from_pretrained:220 - Got text-to-video model root path: /u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/ckpts/hunyuan-video-i2v-720p
2026-01-11 18:52:32.497 | INFO     | hyvideo.inference:from_pretrained:258 - Building model...
2026-01-11 18:52:33.500 | INFO     | hyvideo.inference:load_state_dict:494 - Loading torch model ckpts/hunyuan-video-i2v-720p/transformers/mp_rank_00_model_states.pt...
2026-01-11 18:52:55.199 | INFO     | hyvideo.vae:load_vae:29 - Loading 3D VAE model (884-16c-hy) from: /u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/ckpts/hunyuan-video-i2v-720p/vae
2026-01-11 18:52:56.978 | INFO     | hyvideo.vae:load_vae:55 - VAE to dtype: torch.float16
2026-01-11 18:52:56.988 | INFO     | hyvideo.text_encoder:load_text_encoder:35 - Loading text encoder model (llm-i2v) from: /u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/ckpts/text_encoder_i2v

Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
Loading checkpoint shards:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:11<00:33, 11.27s/it]
Loading checkpoint shards:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:13<00:12,  6.17s/it]
Loading checkpoint shards:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:16<00:04,  4.58s/it]
Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:45<00:00, 14.28s/it]
Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:45<00:00, 11.43s/it]
2026-01-11 18:53:44.599 | INFO     | hyvideo.text_encoder:load_text_encoder:61 - Text encoder to dtype: torch.float16
2026-01-11 18:53:44.603 | INFO     | hyvideo.text_encoder:load_tokenizer:75 - Loading tokenizer (llm-i2v) from: /u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/ckpts/text_encoder_i2v
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2026-01-11 18:53:44.838 | INFO     | hyvideo.text_encoder:load_text_encoder:35 - Loading text encoder model (clipL) from: /u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/ckpts/text_encoder_2
2026-01-11 18:53:46.298 | INFO     | hyvideo.text_encoder:load_text_encoder:61 - Text encoder to dtype: torch.float16
2026-01-11 18:53:46.299 | INFO     | hyvideo.text_encoder:load_tokenizer:75 - Loading tokenizer (clipL) from: /u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/ckpts/text_encoder_2
2026-01-11 18:53:46.529 | INFO     | hyvideo.inference:predict:771 - Input (height, width, video_length) = (1280, 720, 129)
2026-01-11 18:53:48.635 | DEBUG    | hyvideo.inference:get_rotary_pos_embed:690 - actual_num_frames = 129 <= 192, using original RoPE
2026-01-11 18:53:48.671 | DEBUG    | hyvideo.inference:get_rotary_pos_embed:698 - freqs_cos shape: torch.Size([118800, 128]), device: cpu
2026-01-11 18:53:48.671 | DEBUG    | hyvideo.inference:predict:886 - 
                        height: 960
                         width: 960
                  video_length: 129
                        prompt: ['The scene contains a diamond object and a dashed target position (indicated by a dashed outline of the same shape). Keep the dashed target position unchanged. Move the diamond object to the dashed target position along the shortest path, ensuring it completely overlaps with the target.']
                    neg_prompt: ['']
                          seed: 0
                   infer_steps: 50
         num_videos_per_prompt: 1
                guidance_scale: 1.0
                      n_tokens: 118800
                    flow_shift: 7.0
       embedded_guidance_scale: 6.0
                 i2v_stability: True

  0%|          | 0/50 [00:00<?, ?it/s]
  0%|          | 0/50 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/sample_image2video.py", line 65, in <module>
    main()
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/sample_image2video.py", line 32, in main
    outputs = hunyuan_video_sampler.predict(
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/sw/user/python/miniforge3-pytorch-24.11.3/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/inference.py", line 889, in predict
    samples = self.pipeline(
              ^^^^^^^^^^^^^^
  File "/sw/user/python/miniforge3-pytorch-24.11.3/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/diffusion/pipelines/pipeline_hunyuan_video.py", line 1048, in __call__
    noise_pred = self.transformer(  # For an input image (129, 192, 336) (1, 256, 256)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/sw/user/python/miniforge3-pytorch-24.11.3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/sw/user/python/miniforge3-pytorch-24.11.3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/models.py", line 763, in forward
    img, txt = block(*double_block_args)
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/sw/user/python/miniforge3-pytorch-24.11.3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/sw/user/python/miniforge3-pytorch-24.11.3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/models.py", line 233, in forward
    attn = attention(
           ^^^^^^^^^^
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/attenion.py", line 108, in attention
    x = flash_attn_varlen_func(
        ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: 'NoneType' object is not callable

    [27/50] Processing: object_trajectory_0026

  üé¨ Generating: object_trajectory_0026 with hunyuan-video-i2v
     Image: /u/yli8/hokin/video-reason-experiments/data/questions/G-1_object_trajectory_data-generator/object_trajectory_task/object_trajectory_0026/first_frame.png
     Prompt: The scene contains a circle object and a dashed target position (indicated by a ...
Warning: HunyuanVideo requires 60-80GB GPU memory for 720p generation

‚úÖ Inference complete! Output saved to: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0026
   - Generated: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0026/video/video.mp4
   - Question: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0026/question/
     ‚ùå Failed: 2026-01-11 18:54:04.132 | INFO     | hyvideo.inference:from_pretrained:220 - Got text-to-video model root path: /u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/ckpts/hunyuan-video-i2v-720p
2026-01-11 18:54:04.969 | INFO     | hyvideo.inference:from_pretrained:258 - Building model...
2026-01-11 18:54:05.799 | INFO     | hyvideo.inference:load_state_dict:494 - Loading torch model ckpts/hunyuan-video-i2v-720p/transformers/mp_rank_00_model_states.pt...
2026-01-11 18:54:20.347 | INFO     | hyvideo.vae:load_vae:29 - Loading 3D VAE model (884-16c-hy) from: /u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/ckpts/hunyuan-video-i2v-720p/vae
2026-01-11 18:54:21.424 | INFO     | hyvideo.vae:load_vae:55 - VAE to dtype: torch.float16
2026-01-11 18:54:21.434 | INFO     | hyvideo.text_encoder:load_text_encoder:35 - Loading text encoder model (llm-i2v) from: /u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/ckpts/text_encoder_i2v

Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
Loading checkpoint shards:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.59it/s]
Loading checkpoint shards:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:01<00:01,  1.89it/s]
Loading checkpoint shards:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.00it/s]
Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.53it/s]
Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.24it/s]
2026-01-11 18:54:24.652 | INFO     | hyvideo.text_encoder:load_text_encoder:61 - Text encoder to dtype: torch.float16
2026-01-11 18:54:24.656 | INFO     | hyvideo.text_encoder:load_tokenizer:75 - Loading tokenizer (llm-i2v) from: /u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/ckpts/text_encoder_i2v
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2026-01-11 18:54:24.855 | INFO     | hyvideo.text_encoder:load_text_encoder:35 - Loading text encoder model (clipL) from: /u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/ckpts/text_encoder_2
2026-01-11 18:54:25.026 | INFO     | hyvideo.text_encoder:load_text_encoder:61 - Text encoder to dtype: torch.float16
2026-01-11 18:54:25.027 | INFO     | hyvideo.text_encoder:load_tokenizer:75 - Loading tokenizer (clipL) from: /u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/ckpts/text_encoder_2
2026-01-11 18:54:25.227 | INFO     | hyvideo.inference:predict:771 - Input (height, width, video_length) = (1280, 720, 129)
2026-01-11 18:54:25.970 | DEBUG    | hyvideo.inference:get_rotary_pos_embed:690 - actual_num_frames = 129 <= 192, using original RoPE
2026-01-11 18:54:26.000 | DEBUG    | hyvideo.inference:get_rotary_pos_embed:698 - freqs_cos shape: torch.Size([118800, 128]), device: cpu
2026-01-11 18:54:26.001 | DEBUG    | hyvideo.inference:predict:886 - 
                        height: 960
                         width: 960
                  video_length: 129
                        prompt: ['The scene contains a circle object and a dashed target position (indicated by a dashed outline of the same shape). Keep the dashed target position unchanged. Move the circle object to the dashed target position along the shortest path, ensuring it completely overlaps with the target.']
                    neg_prompt: ['']
                          seed: 0
                   infer_steps: 50
         num_videos_per_prompt: 1
                guidance_scale: 1.0
                      n_tokens: 118800
                    flow_shift: 7.0
       embedded_guidance_scale: 6.0
                 i2v_stability: True

  0%|          | 0/50 [00:00<?, ?it/s]
  0%|          | 0/50 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/sample_image2video.py", line 65, in <module>
    main()
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/sample_image2video.py", line 32, in main
    outputs = hunyuan_video_sampler.predict(
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/sw/user/python/miniforge3-pytorch-24.11.3/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/inference.py", line 889, in predict
    samples = self.pipeline(
              ^^^^^^^^^^^^^^
  File "/sw/user/python/miniforge3-pytorch-24.11.3/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/diffusion/pipelines/pipeline_hunyuan_video.py", line 1048, in __call__
    noise_pred = self.transformer(  # For an input image (129, 192, 336) (1, 256, 256)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/sw/user/python/miniforge3-pytorch-24.11.3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/sw/user/python/miniforge3-pytorch-24.11.3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/models.py", line 763, in forward
    img, txt = block(*double_block_args)
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/sw/user/python/miniforge3-pytorch-24.11.3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/sw/user/python/miniforge3-pytorch-24.11.3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/models.py", line 233, in forward
    attn = attention(
           ^^^^^^^^^^
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/attenion.py", line 108, in attention
    x = flash_attn_varlen_func(
        ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: 'NoneType' object is not callable

      ‚ùå Failed: 2026-01-11 18:54:04.132 | INFO     | hyvideo.inference:from_pretrained:220 - Got text-to-video model root path: /u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/ckpts/hunyuan-video-i2v-720p
2026-01-11 18:54:04.969 | INFO     | hyvideo.inference:from_pretrained:258 - Building model...
2026-01-11 18:54:05.799 | INFO     | hyvideo.inference:load_state_dict:494 - Loading torch model ckpts/hunyuan-video-i2v-720p/transformers/mp_rank_00_model_states.pt...
2026-01-11 18:54:20.347 | INFO     | hyvideo.vae:load_vae:29 - Loading 3D VAE model (884-16c-hy) from: /u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/ckpts/hunyuan-video-i2v-720p/vae
2026-01-11 18:54:21.424 | INFO     | hyvideo.vae:load_vae:55 - VAE to dtype: torch.float16
2026-01-11 18:54:21.434 | INFO     | hyvideo.text_encoder:load_text_encoder:35 - Loading text encoder model (llm-i2v) from: /u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/ckpts/text_encoder_i2v

Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
Loading checkpoint shards:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  1.59it/s]
Loading checkpoint shards:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:01<00:01,  1.89it/s]
Loading checkpoint shards:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.00it/s]
Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.53it/s]
Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.24it/s]
2026-01-11 18:54:24.652 | INFO     | hyvideo.text_encoder:load_text_encoder:61 - Text encoder to dtype: torch.float16
2026-01-11 18:54:24.656 | INFO     | hyvideo.text_encoder:load_tokenizer:75 - Loading tokenizer (llm-i2v) from: /u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/ckpts/text_encoder_i2v
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2026-01-11 18:54:24.855 | INFO     | hyvideo.text_encoder:load_text_encoder:35 - Loading text encoder model (clipL) from: /u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/ckpts/text_encoder_2
2026-01-11 18:54:25.026 | INFO     | hyvideo.text_encoder:load_text_encoder:61 - Text encoder to dtype: torch.float16
2026-01-11 18:54:25.027 | INFO     | hyvideo.text_encoder:load_tokenizer:75 - Loading tokenizer (clipL) from: /u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/ckpts/text_encoder_2
2026-01-11 18:54:25.227 | INFO     | hyvideo.inference:predict:771 - Input (height, width, video_length) = (1280, 720, 129)
2026-01-11 18:54:25.970 | DEBUG    | hyvideo.inference:get_rotary_pos_embed:690 - actual_num_frames = 129 <= 192, using original RoPE
2026-01-11 18:54:26.000 | DEBUG    | hyvideo.inference:get_rotary_pos_embed:698 - freqs_cos shape: torch.Size([118800, 128]), device: cpu
2026-01-11 18:54:26.001 | DEBUG    | hyvideo.inference:predict:886 - 
                        height: 960
                         width: 960
                  video_length: 129
                        prompt: ['The scene contains a circle object and a dashed target position (indicated by a dashed outline of the same shape). Keep the dashed target position unchanged. Move the circle object to the dashed target position along the shortest path, ensuring it completely overlaps with the target.']
                    neg_prompt: ['']
                          seed: 0
                   infer_steps: 50
         num_videos_per_prompt: 1
                guidance_scale: 1.0
                      n_tokens: 118800
                    flow_shift: 7.0
       embedded_guidance_scale: 6.0
                 i2v_stability: True

  0%|          | 0/50 [00:00<?, ?it/s]
  0%|          | 0/50 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/sample_image2video.py", line 65, in <module>
    main()
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/sample_image2video.py", line 32, in main
    outputs = hunyuan_video_sampler.predict(
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/sw/user/python/miniforge3-pytorch-24.11.3/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/inference.py", line 889, in predict
    samples = self.pipeline(
              ^^^^^^^^^^^^^^
  File "/sw/user/python/miniforge3-pytorch-24.11.3/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/diffusion/pipelines/pipeline_hunyuan_video.py", line 1048, in __call__
    noise_pred = self.transformer(  # For an input image (129, 192, 336) (1, 256, 256)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/sw/user/python/miniforge3-pytorch-24.11.3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/sw/user/python/miniforge3-pytorch-24.11.3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/models.py", line 763, in forward
    img, txt = block(*double_block_args)
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/sw/user/python/miniforge3-pytorch-24.11.3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/sw/user/python/miniforge3-pytorch-24.11.3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/models.py", line 233, in forward
    attn = attention(
           ^^^^^^^^^^
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/attenion.py", line 108, in attention
    x = flash_attn_varlen_func(
        ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: 'NoneType' object is not callable

    [28/50] Processing: object_trajectory_0027

  üé¨ Generating: object_trajectory_0027 with hunyuan-video-i2v
     Image: /u/yli8/hokin/video-reason-experiments/data/questions/G-1_object_trajectory_data-generator/object_trajectory_task/object_trajectory_0027/first_frame.png
     Prompt: The scene contains a square object and a dashed target position (indicated by a ...
Warning: HunyuanVideo requires 60-80GB GPU memory for 720p generation

‚úÖ Inference complete! Output saved to: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0027
   - Generated: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0027/video/video.mp4
   - Question: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0027/question/
     ‚ùå Failed: 2026-01-11 18:54:37.236 | INFO     | hyvideo.inference:from_pretrained:220 - Got text-to-video model root path: /u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/ckpts/hunyuan-video-i2v-720p
2026-01-11 18:54:37.934 | INFO     | hyvideo.inference:from_pretrained:258 - Building model...
2026-01-11 18:54:38.932 | INFO     | hyvideo.inference:load_state_dict:494 - Loading torch model ckpts/hunyuan-video-i2v-720p/transformers/mp_rank_00_model_states.pt...
2026-01-11 19:03:26.449 | INFO     | hyvideo.vae:load_vae:29 - Loading 3D VAE model (884-16c-hy) from: /u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/ckpts/hunyuan-video-i2v-720p/vae
2026-01-11 19:03:28.679 | INFO     | hyvideo.vae:load_vae:55 - VAE to dtype: torch.float16
2026-01-11 19:03:28.689 | INFO     | hyvideo.text_encoder:load_text_encoder:35 - Loading text encoder model (llm-i2v) from: /u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/ckpts/text_encoder_i2v

Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
Loading checkpoint shards:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:11<00:34, 11.36s/it]
Loading checkpoint shards:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:14<00:13,  6.58s/it]
Loading checkpoint shards:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:17<00:04,  4.77s/it]
Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:59<00:00, 19.43s/it]
Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:59<00:00, 14.78s/it]
2026-01-11 19:04:30.854 | INFO     | hyvideo.text_encoder:load_text_encoder:61 - Text encoder to dtype: torch.float16
2026-01-11 19:04:30.858 | INFO     | hyvideo.text_encoder:load_tokenizer:75 - Loading tokenizer (llm-i2v) from: /u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/ckpts/text_encoder_i2v
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2026-01-11 19:04:31.105 | INFO     | hyvideo.text_encoder:load_text_encoder:35 - Loading text encoder model (clipL) from: /u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/ckpts/text_encoder_2
2026-01-11 19:04:32.531 | INFO     | hyvideo.text_encoder:load_text_encoder:61 - Text encoder to dtype: torch.float16
2026-01-11 19:04:32.533 | INFO     | hyvideo.text_encoder:load_tokenizer:75 - Loading tokenizer (clipL) from: /u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/ckpts/text_encoder_2
2026-01-11 19:06:09.517 | INFO     | hyvideo.inference:predict:771 - Input (height, width, video_length) = (1280, 720, 129)
2026-01-11 19:06:11.302 | DEBUG    | hyvideo.inference:get_rotary_pos_embed:690 - actual_num_frames = 129 <= 192, using original RoPE
2026-01-11 19:06:11.345 | DEBUG    | hyvideo.inference:get_rotary_pos_embed:698 - freqs_cos shape: torch.Size([118800, 128]), device: cpu
2026-01-11 19:06:11.345 | DEBUG    | hyvideo.inference:predict:886 - 
                        height: 960
                         width: 960
                  video_length: 129
                        prompt: ['The scene contains a square object and a dashed target position (indicated by a dashed outline of the same shape). Keep the dashed target position unchanged. Move the square object to the dashed target position along the shortest path, ensuring it completely overlaps with the target.']
                    neg_prompt: ['']
                          seed: 0
                   infer_steps: 50
         num_videos_per_prompt: 1
                guidance_scale: 1.0
                      n_tokens: 118800
                    flow_shift: 7.0
       embedded_guidance_scale: 6.0
                 i2v_stability: True

  0%|          | 0/50 [00:00<?, ?it/s]
  0%|          | 0/50 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/sample_image2video.py", line 65, in <module>
    main()
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/sample_image2video.py", line 32, in main
    outputs = hunyuan_video_sampler.predict(
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/sw/user/python/miniforge3-pytorch-24.11.3/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/inference.py", line 889, in predict
    samples = self.pipeline(
              ^^^^^^^^^^^^^^
  File "/sw/user/python/miniforge3-pytorch-24.11.3/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/diffusion/pipelines/pipeline_hunyuan_video.py", line 1048, in __call__
    noise_pred = self.transformer(  # For an input image (129, 192, 336) (1, 256, 256)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/sw/user/python/miniforge3-pytorch-24.11.3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/sw/user/python/miniforge3-pytorch-24.11.3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/models.py", line 763, in forward
    img, txt = block(*double_block_args)
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/sw/user/python/miniforge3-pytorch-24.11.3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/sw/user/python/miniforge3-pytorch-24.11.3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/models.py", line 233, in forward
    attn = attention(
           ^^^^^^^^^^
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/attenion.py", line 108, in attention
    x = flash_attn_varlen_func(
        ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: 'NoneType' object is not callable

      ‚ùå Failed: 2026-01-11 18:54:37.236 | INFO     | hyvideo.inference:from_pretrained:220 - Got text-to-video model root path: /u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/ckpts/hunyuan-video-i2v-720p
2026-01-11 18:54:37.934 | INFO     | hyvideo.inference:from_pretrained:258 - Building model...
2026-01-11 18:54:38.932 | INFO     | hyvideo.inference:load_state_dict:494 - Loading torch model ckpts/hunyuan-video-i2v-720p/transformers/mp_rank_00_model_states.pt...
2026-01-11 19:03:26.449 | INFO     | hyvideo.vae:load_vae:29 - Loading 3D VAE model (884-16c-hy) from: /u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/ckpts/hunyuan-video-i2v-720p/vae
2026-01-11 19:03:28.679 | INFO     | hyvideo.vae:load_vae:55 - VAE to dtype: torch.float16
2026-01-11 19:03:28.689 | INFO     | hyvideo.text_encoder:load_text_encoder:35 - Loading text encoder model (llm-i2v) from: /u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/ckpts/text_encoder_i2v

Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
Loading checkpoint shards:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:11<00:34, 11.36s/it]
Loading checkpoint shards:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:14<00:13,  6.58s/it]
Loading checkpoint shards:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:17<00:04,  4.77s/it]
Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:59<00:00, 19.43s/it]
Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:59<00:00, 14.78s/it]
2026-01-11 19:04:30.854 | INFO     | hyvideo.text_encoder:load_text_encoder:61 - Text encoder to dtype: torch.float16
2026-01-11 19:04:30.858 | INFO     | hyvideo.text_encoder:load_tokenizer:75 - Loading tokenizer (llm-i2v) from: /u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/ckpts/text_encoder_i2v
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2026-01-11 19:04:31.105 | INFO     | hyvideo.text_encoder:load_text_encoder:35 - Loading text encoder model (clipL) from: /u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/ckpts/text_encoder_2
2026-01-11 19:04:32.531 | INFO     | hyvideo.text_encoder:load_text_encoder:61 - Text encoder to dtype: torch.float16
2026-01-11 19:04:32.533 | INFO     | hyvideo.text_encoder:load_tokenizer:75 - Loading tokenizer (clipL) from: /u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/ckpts/text_encoder_2
2026-01-11 19:06:09.517 | INFO     | hyvideo.inference:predict:771 - Input (height, width, video_length) = (1280, 720, 129)
2026-01-11 19:06:11.302 | DEBUG    | hyvideo.inference:get_rotary_pos_embed:690 - actual_num_frames = 129 <= 192, using original RoPE
2026-01-11 19:06:11.345 | DEBUG    | hyvideo.inference:get_rotary_pos_embed:698 - freqs_cos shape: torch.Size([118800, 128]), device: cpu
2026-01-11 19:06:11.345 | DEBUG    | hyvideo.inference:predict:886 - 
                        height: 960
                         width: 960
                  video_length: 129
                        prompt: ['The scene contains a square object and a dashed target position (indicated by a dashed outline of the same shape). Keep the dashed target position unchanged. Move the square object to the dashed target position along the shortest path, ensuring it completely overlaps with the target.']
                    neg_prompt: ['']
                          seed: 0
                   infer_steps: 50
         num_videos_per_prompt: 1
                guidance_scale: 1.0
                      n_tokens: 118800
                    flow_shift: 7.0
       embedded_guidance_scale: 6.0
                 i2v_stability: True

  0%|          | 0/50 [00:00<?, ?it/s]
  0%|          | 0/50 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/sample_image2video.py", line 65, in <module>
    main()
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/sample_image2video.py", line 32, in main
    outputs = hunyuan_video_sampler.predict(
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/sw/user/python/miniforge3-pytorch-24.11.3/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/inference.py", line 889, in predict
    samples = self.pipeline(
              ^^^^^^^^^^^^^^
  File "/sw/user/python/miniforge3-pytorch-24.11.3/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/diffusion/pipelines/pipeline_hunyuan_video.py", line 1048, in __call__
    noise_pred = self.transformer(  # For an input image (129, 192, 336) (1, 256, 256)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/sw/user/python/miniforge3-pytorch-24.11.3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/sw/user/python/miniforge3-pytorch-24.11.3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/models.py", line 763, in forward
    img, txt = block(*double_block_args)
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/sw/user/python/miniforge3-pytorch-24.11.3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/sw/user/python/miniforge3-pytorch-24.11.3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/models.py", line 233, in forward
    attn = attention(
           ^^^^^^^^^^
  File "/u/yli8/hokin/video-reason-experiments/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/modules/attenion.py", line 108, in attention
    x = flash_attn_varlen_func(
        ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: 'NoneType' object is not callable

    [29/50] Processing: object_trajectory_0028

  üé¨ Generating: object_trajectory_0028 with hunyuan-video-i2v
     Image: /u/yli8/hokin/video-reason-experiments/data/questions/G-1_object_trajectory_data-generator/object_trajectory_task/object_trajectory_0028/first_frame.png
     Prompt: The scene contains a square object and a dashed target position (indicated by a ...
Warning: HunyuanVideo requires 60-80GB GPU memory for 720p generation

‚úÖ Inference complete! Output saved to: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0028
   - Generated: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0028/video/video.mp4
   - Question: /u/yli8/hokin/video-reason-experiments/data/outputs/hunyuan-video-i2v/object_trajectory_task/object_trajectory_0028/question/
     ‚úÖ Success! Structured output saved to: N/A
      ‚úÖ Completed successfully
    [30/50] Processing: object_trajectory_0029

  üé¨ Generating: object_trajectory_0029 with hunyuan-video-i2v
     Image: /u/yli8/hokin/video-reason-experiments/data/questions/G-1_object_trajectory_data-generator/object_trajectory_task/object_trajectory_0029/first_frame.png
     Prompt: The scene contains a triangle object and a dashed target position (indicated by ...
Warning: HunyuanVideo requires 60-80GB GPU memory for 720p generation
